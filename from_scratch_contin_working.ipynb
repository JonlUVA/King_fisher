{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea55ff5a-5e53-42c2-97e9-0114d3713916",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabb601c-5990-42cc-a2ba-ef7eb5c4c5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import opendatasets as od\n",
    "import pandas\n",
    " \n",
    "od.download(\"https://www.kaggle.com/competitions/feather-in-focus/data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbef826-114f-41b5-95d1-5b877b5e4b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.kaggle.com/code/chekoduadarsh/starters-guide-convolutional-xgboost/notebook\n",
    "#https://www.kaggle.com/code/pedrolucasbritodes/bird-image-classification-cnn-89-accuracy/notebook\n",
    "#https://stats.stackexchange.com/questions/404809/is-it-advisable-to-use-output-from-a-ml-model-as-a-feature-in-another-ml-model\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.applications import InceptionV3\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import random\n",
    "\n",
    "#how many epchos still revert\n",
    "patience1 = 3\n",
    "\n",
    "base_learning_rate = 0.001 \n",
    "#number before fine_tuning\n",
    "number_epcho1 = 20\n",
    "#number after fine_tuning\n",
    "number_epcho2 = 20\n",
    "number_class = 200\n",
    "#needs to be the same number of classes\n",
    "output_Neurons = 200\n",
    "Neurons = 512\n",
    "batch_size = 32\n",
    "drop_out_rate = 0.3\n",
    "image_shape = (224,224)\n",
    "image_shape_full = (224,224,3)\n",
    "current_directory = \"feather-in-focus/\"\n",
    "#current_directory = \"feather-in-focus/\"\n",
    "blur_number = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1ccf2b-4ac4-4cae-aac6-0b88a172b3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading files \n",
    "class_names2 = np.load('{}class_names.npy'.format(current_directory), allow_pickle=True).item()\n",
    "\n",
    "#load all files because why not\n",
    "test_image_path = pd.read_csv('{}test_images_path.csv'.format(current_directory))\n",
    "test_image_path['total_path'] = current_directory + \"/test_images\" + test_image_path['image_path'] \n",
    "test_image_path['total_path'] = test_image_path['total_path'].str.replace(\"\\\\\", \"/\" )\n",
    "test_image = pd.read_csv('{}test_images_sample.csv'.format(current_directory))\n",
    "\n",
    "\n",
    "#importing training data \n",
    "train_image = pd.read_csv('{}train_images.csv'.format(current_directory))\n",
    "train_image['total_path'] = current_directory + \"train_images\" + train_image['image_path']\n",
    "train_image['total_path'] = train_image['total_path'].str.replace(\"\\\\\", \"/\" )\n",
    "train_image['short_name'] = train_image['image_path'].str.rsplit('/', n=1).str[-1]\n",
    "\n",
    "#train_image['label'] = train_image['label'].apply(str)\n",
    "train_image.head()\n",
    "\n",
    "#importing bird data \n",
    "bird_data = pd.read_csv('{}output_birds.csv'.format(current_directory))\n",
    "\n",
    "\n",
    "bird_data2 = train_image.merge(bird_data, how = 'left', left_on = 'label', right_on = 'bird_number_x')\n",
    "bird_data2['label'] = bird_data2['label'].apply(str)\n",
    "M1 = 'Tarsus.Length'\n",
    "M2 = 'Hand-Wing.Index'\n",
    "M3 = 'Beak.Depth'\n",
    "bird_data2 = bird_data2[['image_path','short_name', 'label', 'total_path', 'bird_class', M1,\n",
    "                        M2, M3]]\n",
    "\n",
    "bird_data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5bc2d74-8a5d-4d7e-8459-a280f3515c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "Wing_min = bird_data2[M1].min()\n",
    "Wing_max = bird_data2[M1].max()\n",
    "bird_data2[M1] =  (bird_data2[M1] - Wing_min) / (Wing_max - Wing_min)\n",
    "\n",
    "#Wing_mean = bird_data2['Wing.Length'].mean()\n",
    "#Wing_std = bird_data2['Wing.Length'].std()\n",
    "#bird_data2['Wing.Length'] =  (bird_data2['Wing.Length'] - Wing_mean) / (Wing_std)\n",
    "\n",
    "\n",
    "tail_min = bird_data2[M2].min()\n",
    "tail_max = bird_data2[M2].max()\n",
    "#tail_mean = bird_data2['Tail.Length'].mean()\n",
    "#tail_std = bird_data2['Tail.Length'].std()\n",
    "\n",
    "#bird_data2['Tail.Length'] = (bird_data2['Tail.Length'] - tail_mean ) / tail_std \n",
    "\n",
    "bird_data2[M2] = (bird_data2[M2] - tail_min ) / (tail_max - tail_min) \n",
    "mass_min = bird_data2[M3].min()\n",
    "mass_max = bird_data2[M3].max()\n",
    "#mass_mean = bird_data2['Beak.Width'].mean()\n",
    "#mass_std = bird_data2['Beak.Width'].std()\n",
    "#bird_data2['Beak.Width'] = (bird_data2['Beak.Width'] - mass_mean) / mass_std\n",
    "bird_data2[M3] = (bird_data2[M3] - mass_min) / (mass_max - mass_min)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming 'df' is your Pandas DataFrame\n",
    "# Check for missing or null values in any column\n",
    "if bird_data2[[M1,M2, M3]].isnull().values.any():\n",
    "    print(\"There are missing or null values in the DataFrame.\")\n",
    "    # Return True or perform necessary actions\n",
    "else:\n",
    "    print(\"There are no missing or null values in the DataFrame.\")\n",
    "    # Return False or proceed accordingly\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c216ed-d088-45d8-a6f6-0d3e8f125e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to add a k-folds, i have stratified so it works a bit better\n",
    "train, valid = train_test_split(bird_data2, \n",
    "                    test_size=0.2,\n",
    "                    #stratify = train_image['label'],\n",
    "                    random_state=420)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc74e11-5eff-4f7c-a0fd-9587b39b139e",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid.to_csv('valid_csv.csv')\n",
    "train.to_csv('train_csv.csv')\n",
    "#valid = pd.read_csv('valid_csv.csv')\n",
    "#train = pd.read_csv('train_csv.csv')\n",
    "#valid['label'] = valid['label'].astype(str)\n",
    "#train['label'] = train['label'].astype(str)\n",
    "bird_data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e25921-7d8b-4b3d-bcf1-70617596cf77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#deleting images if they are there \n",
    "\n",
    "folder_path = \"custom_aug\"  # Replace 'path_to_folder' with the actual path to your folder\n",
    "\n",
    "# Iterate through all files in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    file_path = os.path.join(folder_path, filename)\n",
    "    \n",
    "    # Check if the file is an image (you might want to refine this check based on your specific file types)\n",
    "    if os.path.isfile(file_path) and (filename.endswith('.jpg') or filename.endswith('.png')):\n",
    "        os.remove(file_path)\n",
    "        #print(f\"Deleted: {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbecc552-6ca0-4e90-af90-6d140f55cc01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47aacb31-9885-47e8-97a5-1da94b3132bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from PIL import Image, ImageFilter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def custom_blur(dataframe, label, name, folder, blur_number):\n",
    "    img = Image.open(dataframe['total_path']).filter(ImageFilter.GaussianBlur(blur_number))\n",
    "    img.save(f\"{folder}/blur_{dataframe[name]}\")\n",
    "\n",
    "    return {\n",
    "        \"image_path\": f\"{folder}/blur_{dataframe[name]}\",\n",
    "        M1: dataframe[M1],\n",
    "        M2: dataframe[M2],\n",
    "        M3: dataframe[M3],\n",
    "        \"total_path\": f\"{folder}/blur_{dataframe[name]}\",\n",
    "        \"short_name\": f\"blur_{dataframe[name]}\",\n",
    "        \"label\": dataframe[label],\n",
    "    }\n",
    "\n",
    "def custom_getPerspectiveTransform(dataframe, label, name, folder):\n",
    "    input_image = cv2.imread(dataframe['total_path'])\n",
    "    height, width = input_image.shape[:2]\n",
    "    \n",
    "    objPoints = np.float32([[0, 0], \n",
    "                            [int(np.random.uniform(0.75, 0.85) * width), 0], \n",
    "                            [0, int(np.random.uniform(0.85, 0.95) * height)], \n",
    "                            [int(np.random.uniform(0.75, 0.85) * width), int(np.random.uniform(0.65, 0.75) * height)]])\n",
    "    \n",
    "    imgPts = np.float32([\n",
    "        [np.random.uniform(0.10, 0.20) * width, np.random.uniform(0.20, 0.30) * height],\n",
    "        [np.random.uniform(0.75, 0.85) * width, np.random.uniform(0.15, 0.25) * height],\n",
    "        [np.random.uniform(0.05, 0.15) * width, np.random.uniform(0.65, 0.75) * height],\n",
    "        [np.random.uniform(0.85, 0.95) * width, np.random.uniform(0.65, 0.75) * height]\n",
    "    ])\n",
    "    \n",
    "    matrix = cv2.getPerspectiveTransform(imgPts, objPoints)\n",
    "    result = cv2.warpPerspective(input_image, matrix, (width, height))\n",
    "    \n",
    "    cv2.imwrite(f\"{folder}/persp_{dataframe[name]}\", result)\n",
    "\n",
    "    return {\n",
    "        \"image_path\": f\"{folder}/persp_{dataframe[name]}\",\n",
    "        M1: dataframe[M1],\n",
    "        M2: dataframe[M2],\n",
    "        M3: dataframe[M3],\n",
    "        \"total_path\": f\"{folder}/persp_{dataframe[name]}\",\n",
    "        \"short_name\": f\"persp_{dataframe[name]}\",\n",
    "        \"label\": dataframe[label],\n",
    "    }\n",
    "\n",
    "loc = \"custom_aug\" \n",
    "blur_number = 5  # Specify your blur number\n",
    "\n",
    "train_augmented_data = []\n",
    "valid_augmented_data = []\n",
    "\n",
    "for index, row in train.iterrows():\n",
    "    train_augmented_data.append(custom_getPerspectiveTransform(row, 'label', 'short_name', loc))\n",
    "    train_augmented_data.append(custom_blur(row, 'label', 'short_name', loc, blur_number))\n",
    "\n",
    "for index, row in valid.iterrows():\n",
    "    valid_augmented_data.append(custom_getPerspectiveTransform(row, 'label', 'short_name', loc))\n",
    "    valid_augmented_data.append(custom_blur(row, 'label', 'short_name', loc, blur_number))\n",
    "\n",
    "# Create augmented DataFrames\n",
    "persp_train_dataframe = pd.DataFrame(train_augmented_data)\n",
    "persp_valid_dataframe = pd.DataFrame(valid_augmented_data)\n",
    "\n",
    "# Concatenate augmented DataFrames with original DataFrames\n",
    "train = pd.concat([train, persp_train_dataframe], ignore_index=True, sort=False)\n",
    "valid = pd.concat([valid, persp_valid_dataframe], ignore_index=True, sort=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23b9745-627c-4dc6-9296-1b8c0b3d212d",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b8bb47-9f6c-4815-b420-60f7e3d321fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this creates the type of augmentation that is done! \n",
    "datagen = ImageDataGenerator(\n",
    "    #rotation_range=15,\n",
    "    rotation_range=90,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range = 15,\n",
    "    horizontal_flip = True,\n",
    "    zoom_range = 0.20)\n",
    "#look at aug from group chat \n",
    "\n",
    "#okay this method seems WAY better. only ever use aug images\n",
    "train_generator = datagen.flow_from_dataframe(\n",
    "    dataframe=train,\n",
    "    x_col='total_path',\n",
    "    y_col=[M1,M2,M3],\n",
    "           # Assuming 'label' contains the continuous values\n",
    "    color_mode='rgb',\n",
    "    target_size=image_shape,\n",
    "    class_mode='raw',  # Use 'raw' for continuous values instead of 'categorical'\n",
    "    batch_size=batch_size  # Define your batch size\n",
    ")\n",
    "\n",
    "\n",
    "valid_generator=datagen.flow_from_dataframe(\n",
    "dataframe=valid,\n",
    "x_col='total_path',\n",
    "y_col=[M1,M2,M3],  # Assuming 'label' contains the continuous values\n",
    "color_mode='rgb',\n",
    "target_size=image_shape,\n",
    "class_mode='raw',  # Use 'raw' for continuous values instead of 'categorical'\n",
    "batch_size=batch_size  # Define your batch size\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4db9d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e895cd6a-9967-4f8a-9b80-ceba3ad044a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5790fb1a-c369-4cf9-8da9-d6349d82272f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import ResNet50, InceptionV3\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, BatchNormalization, Dropout, GlobalAveragePooling2D, Input\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout\n",
    "import tensorflow as tf\n",
    "\n",
    "dr = 0.4\n",
    "IM_WIDTH, IM_HEIGHT = 224, 224\n",
    "\n",
    "class MultiOutputBird():\n",
    "    def __init__(self):\n",
    "        self.base_model_resnet = ResNet50(\n",
    "            include_top=False,\n",
    "            input_shape=(IM_HEIGHT, IM_WIDTH, 3),\n",
    "            pooling='avg',\n",
    "            weights='imagenet'\n",
    "        )\n",
    "        #self.base_model_resnet.trainable = False\n",
    "\n",
    "        self.base_model_inception = InceptionV3(\n",
    "            include_top=False,\n",
    "            input_shape=(IM_HEIGHT, IM_WIDTH, 3),\n",
    "            pooling='avg',\n",
    "            weights='imagenet'\n",
    "        )\n",
    "        \n",
    "        for layer in self.base_model_inception.layers[:-10]:\n",
    "            layer.trainable = False\n",
    "\n",
    "        for layer in self.base_model_resnet.layers[:-10]:\n",
    "            layer.trainable = False\n",
    "\n",
    "        #self.base_model_inception.trainable = False\n",
    "    def tail_length_branch(self, inputs, dropout_rate=0.3, l2_reg=0.02):\n",
    "        # Hidden layer 1\n",
    "        x = Dense(1024)(inputs)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = tf.keras.activations.relu(x)\n",
    "        x = Dropout(dropout_rate)(x)\n",
    "\n",
    "        # Hidden layer 2\n",
    "        x = Dense(512, activation=\"relu\", kernel_regularizer=tf.keras.regularizers.l2(l2_reg))(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = tf.keras.activations.relu(x)\n",
    "        x = Dropout(dropout_rate)(x)\n",
    "\n",
    "        # Hidden layer 3\n",
    "        x = Dense(512)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = tf.keras.activations.relu(x)\n",
    "\n",
    "        # Output layer\n",
    "        x = Dense(1, activation='linear', name=\"{}_output\".format(M2))(x)\n",
    "        return x\n",
    "\n",
    "    def tail_length_branch(self, inputs, dropout_rate=0.3, l2_reg=0.02):   \n",
    "        x = Dense(1024)(inputs)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = tf.keras.activations.relu(x)\n",
    "        x = Dropout(dropout_rate)(x)\n",
    "\n",
    "        # Hidden layer 2\n",
    "        x = Dense(512, activation=\"relu\", kernel_regularizer=tf.keras.regularizers.l2(l2_reg))(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = tf.keras.activations.relu(x)\n",
    "        x = Dropout(dropout_rate)(x)\n",
    "\n",
    "        # Hidden layer 3\n",
    "        x = Dense(512)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = tf.keras.activations.relu(x)\n",
    "        \n",
    "        x = Dense(1, activation='linear',  name='{}_output'.format(M2))(x)\n",
    "        return x\n",
    "\n",
    "    def beak_branch(self, inputs, dropout_rate=0.3, l2_reg=0.02):   \n",
    "        x = Dense(1024)(inputs)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = tf.keras.activations.relu(x)\n",
    "        x = Dropout(dropout_rate)(x)\n",
    "\n",
    "        # Hidden layer 2\n",
    "        x = Dense(512, activation=\"relu\", kernel_regularizer=tf.keras.regularizers.l2(l2_reg))(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = tf.keras.activations.relu(x)\n",
    "        x = Dropout(dropout_rate)(x)\n",
    "\n",
    "        # Hidden layer 3\n",
    "        x = Dense(512)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = tf.keras.activations.relu(x)\n",
    "        \n",
    "        x = Dense(1, activation='linear', name=\"{}_output\".format(M3))(x)\n",
    "        return x\n",
    "    \n",
    "    def wing_length_branch(self, inputs, dropout_rate=0.3, l2_reg=0.02):   \n",
    "        x = Dense(1024)(inputs)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = tf.keras.activations.relu(x)\n",
    "        x = Dropout(dropout_rate)(x)\n",
    "\n",
    "        # Hidden layer 2\n",
    "        x = Dense(512, activation=\"relu\", kernel_regularizer=tf.keras.regularizers.l2(l2_reg))(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = tf.keras.activations.relu(x)\n",
    "        x = Dropout(dropout_rate)(x)\n",
    "\n",
    "        # Hidden layer 3\n",
    "        x = Dense(512)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = tf.keras.activations.relu(x)\n",
    "        \n",
    "        x = Dense(1, activation='linear', name='{}_output'.format(M1))(x)\n",
    "        return x\n",
    "    \n",
    "    def assemble_full_model(self):\n",
    "        input_resnet = Input(shape=(IM_HEIGHT, IM_WIDTH, 3))\n",
    "        input_inception = Input(shape=(IM_HEIGHT, IM_WIDTH, 3))\n",
    "\n",
    "        x_resnet = self.base_model_resnet(input_resnet)\n",
    "        x_inception = self.base_model_inception(input_resnet)\n",
    "\n",
    "        merged = tf.keras.layers.concatenate([x_resnet, x_inception])\n",
    "\n",
    "        M2_output = self.tail_length_branch(merged)\n",
    "        M3_output = self.beak_branch(merged)\n",
    "        M1_output = self.wing_length_branch(merged)\n",
    "\n",
    "        model = Model(inputs=input_resnet, outputs=[M1_output, M2_output, M3_output], name=\"multi_output_bird_net\")\n",
    "        return model\n",
    "\n",
    "# Example usage:\n",
    "model_builder = MultiOutputBird()\n",
    "model = model_builder.assemble_full_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a785ac50-2355-4f0b-b800-8549c013961a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a201662-9e64-40b8-9a8f-681ae0e1f459",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "epochs = 15\n",
    "adam_optimizer = tf.keras.optimizers.Adam(learning_rate=base_learning_rate)\n",
    "\n",
    "model.compile(optimizer=adam_optimizer,\n",
    "              loss={\n",
    "                  '{}_output'.format(M1): 'mse',\n",
    "                  '{}_output'.format(M2): 'mse',\n",
    "                  '{}_output'.format(M3): 'mse'},\n",
    "              metrics={\n",
    "                  '{}_output'.format(M1): 'mae',\n",
    "                  '{}_output'.format(M2): 'mae',\n",
    "                  '{}_output'.format(M3): 'mae'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cec012-974f-448d-81f8-b78a9c1c2b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "    patience=10,\n",
    "    min_delta=0.001,\n",
    "    restore_best_weights=True,)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a63f0c0-68a6-45c8-9af8-a8280559e601",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=valid_generator,\n",
    "    epochs=10,\n",
    "    batch_size=32,\n",
    "    callbacks=[reduce_lr, early_stop]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d868fca-46ec-439f-882f-a6e24a7a93cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from matplotlib import pyplot as plt\n",
    "plt.clf() \n",
    "plt.plot(history.history['{}_output_mae'.format(M1)])\n",
    "plt.plot(history.history['val_{}_output_mae'.format(M1)])\n",
    "plt.title('model accuracy {}_output'.format(M1))\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.savefig('continous_result_{}.png'.format(M1))\n",
    "plt.clf() \n",
    "\n",
    "import keras\n",
    "from matplotlib import pyplot as plt\n",
    "plt.plot(history.history['{}_output_mae'.format(M2)])\n",
    "plt.plot(history.history['val_{}_output_mae'.format(M2)])\n",
    "plt.title('model accuracy {}'.format(M2))\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.savefig('continous_result_wing.png')\n",
    "plt.clf() \n",
    "\n",
    "\n",
    "import keras\n",
    "from matplotlib import pyplot as plt\n",
    "plt.plot(history.history['val_{}_output_mae'.format(M3)])\n",
    "plt.plot(history.history['{}_output_mae'.format(M3)])\n",
    "plt.title('model accuracy {}'.format(M3))\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.savefig('continous_result_tail.png'.format(M1))\n",
    "plt.clf() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37765a38-cbcc-4ae5-bc40-b3fdfc22184c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "current_directory = \"feather-in-focus\"\n",
    "model.save('{}/keras_final_continous.keras'.format(current_directory))\n",
    "\n",
    "\n",
    "# image folder\n",
    "folder_path = '{}/test_images/test_images/'.format(current_directory)\n",
    "# path to model\n",
    "model_path = '{}/keras_final_continous.keras'.format(current_directory)\n",
    "# dimensions of images\n",
    "img_width, img_height = 224, 224\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a09f44c-5270-4428-aa43-03f0a9b6726c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "import keras.utils as image\n",
    "# load the trained model\n",
    "adam_optimizer = tf.keras.optimizers.Adam(learning_rate=base_learning_rate)\n",
    "model_path = '{}/keras_final_continous.keras'.format(current_directory)\n",
    "model = load_model(model_path)\n",
    "model.compile(optimizer=adam_optimizer,\n",
    "              loss={\n",
    "                  '{}_output'.format(M1): 'mse',\n",
    "                  '{}_output'.format(M2): 'mse',\n",
    "                  '{}_output'.format(M3): 'mse'},\n",
    "              metrics={\n",
    "                  '{}_output'.format(M1): 'mae',\n",
    "                  '{}_output'.format(M2): 'mae',\n",
    "                  '{}_output'.format(M3): 'mae'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42881324-a0a4-4a0b-874f-c510dfc87961",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from heapq import nlargest\n",
    "\n",
    "def closest_indices_mask(array, value, num):\n",
    "    closest_indices = []\n",
    "    distances = []\n",
    "\n",
    "    for i, arr_value in enumerate(array):\n",
    "        distance = np.linalg.norm(np.array(arr_value) - np.array(value))\n",
    "        if len(closest_indices) < num:\n",
    "            closest_indices.append((i, distance))\n",
    "            distances.append(distance)\n",
    "        else:\n",
    "            max_distance = max(distances)\n",
    "            if distance < max_distance:\n",
    "                max_index = distances.index(max_distance)\n",
    "                closest_indices[max_index] = (i, distance)\n",
    "                distances[max_index] = distance\n",
    "\n",
    "    closest_indices.sort(key=lambda x: x[1])  # Sort by distance\n",
    "    closest_indices = [index for index, _ in closest_indices]\n",
    "\n",
    "    closest_mask = np.zeros_like(array)\n",
    "    closest_mask[closest_indices] = 1\n",
    "    return closest_mask[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfb8c1a-3551-4bb8-9440-2a311384c771",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = list()\n",
    "images = []\n",
    "folder_path = 'feather-in-focus/train_images/train_images'  \n",
    "#folder_path = 'feather-in-focus/test_images/test_images' \n",
    "for img_name in os.listdir(folder_path):\n",
    "    img_path = os.path.join(folder_path, img_name)\n",
    "    # Check if the item is a file (not a directory)\n",
    "    if os.path.isfile(img_path):\n",
    "        name.append(img_name)\n",
    "        img = image.load_img(img_path, target_size=image_shape)\n",
    "        img = image.img_to_array(img)\n",
    "        img = np.expand_dims(img, axis=0)\n",
    "        images.append(img)\n",
    "        # Process the image further as needed\n",
    "    else:\n",
    "        # Skip directories\n",
    "        continue\n",
    "        \n",
    "# stack up images list to pass for prediction\n",
    "images = np.vstack(images)\n",
    "classes = model.predict(images, batch_size=10)\n",
    "#classes_x=np.argmax(classes,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76975062-ddbf-4fa0-99da-eb6399a433ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [M1, M2, M3, 'label']\n",
    "idea = bird_data2[cols].sort_values(by=['label']).drop_duplicates()\n",
    "cols = [M1, M2, M3]\n",
    "idea  = idea[cols]\n",
    "array2 = idea.to_numpy().tolist()\n",
    "\n",
    "result = [[classes[0][i], classes[1][i], classes[2][i]] for i in range(min(len(classes[0]), len(classes[1]), len(classes[2])))]\n",
    "distances = []\n",
    "for arr1 in result:\n",
    "    distances_to_arr1 = []\n",
    "    for arr2 in array2:\n",
    "        # Calculate Euclidean distance between elements in arr1 and arr2\n",
    "        distance = np.linalg.norm(np.array(arr1) - np.array(arr2))\n",
    "        distances_to_arr1.append(distance)\n",
    "    distances.append(distances_to_arr1)\n",
    "\n",
    "print(distances)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17ede29-bd65-4e52-a489-86882228deb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns = [ '{}'.format(M1), '{}'.format(M2), '{}'.format(M3), 'label']\n",
    "\n",
    "dictionary = dict()\n",
    "for index, row in bird_data2[selected_columns].iterrows():\n",
    "    key = (row['{}'.format(M1)], row['{}'.format(M2)], row['{}'.format(M3)])\n",
    "    value = row['label']\n",
    "    dictionary[key] = value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a414eda-5274-49fc-a6e3-7a00f495e2e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac695906-3c47-46ab-ba81-1217f3ed4189",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns = ['Wing.Length','Tail.Length','Beak.Width', 'label']\n",
    "\n",
    "idea = bird_data2[selected_columns].drop_duplicates().sort_values('label')\n",
    "idea = idea[['Wing.Length','Tail.Length','Beak.Width']].values.tolist()\n",
    "measures = idea\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bffb285-f387-47dd-9daa-e9d03c711b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cols = [M1,M2,M3 ,'label']\n",
    "idea = bird_data2[cols].sort_values(by=['label']).drop_duplicates()\n",
    "cols = [M1,M2,M3]\n",
    "idea  = idea[cols]\n",
    "array2 = idea.to_numpy().tolist()\n",
    "#array2\n",
    "\n",
    "\n",
    "result = [[classes[0][i], classes[1][i], classes[2][i]] for i in range(min(len(classes[0]), len(classes[1]), len(classes[2])))]\n",
    "distances = []\n",
    "for arr1 in result:\n",
    "    distances_to_arr1 = []\n",
    "    for arr2 in array2:\n",
    "        # Calculate Euclidean distance between elements in arr1 and arr2\n",
    "        distance = np.linalg.norm(np.array(arr1) - np.array(arr2))\n",
    "        distances_to_arr1.append(distance)\n",
    "    distances.append(distances_to_arr1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7729d27-0fdd-49e0-98b9-34bb0d641e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save numpy array as npy file\n",
    "from numpy import asarray\n",
    "from numpy import save\n",
    "# define data\n",
    "data = asarray([[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]])\n",
    "# save to npy file\n",
    "save('data_lookup.npy', array2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb5b73f-46d1-4ade-bd21-1be5f451ca92",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.DataFrame(\n",
    "    {'id': name,\n",
    "     '{}_P'.format(M1): classes[0].tolist(),\n",
    "     '{}_P'.format(M2): classes[1].tolist(),\n",
    "     '{}_P'.format(M3): classes[2].tolist(),\n",
    "    })\n",
    "final_df['{}_P'.format(M1)] = final_df['{}_P'.format(M1)].apply(lambda x: float(x[0]))\n",
    "final_df['{}_P'.format(M2)] = final_df['{}_P'.format(M2)].apply(lambda x: float(x[0]))\n",
    "final_df['{}_P'.format(M3)] = final_df['{}_P'.format(M3)].apply(lambda x: float(x[0]))\n",
    "final_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be762e59-9e45-46c4-831d-f92bf1a6bb7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1e4580-0c85-4fb8-91b0-a31280c86dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def find_closest_values(dictionary, dataframe, columns,num):\n",
    "    closest_values = []\n",
    "\n",
    "    for _, row in dataframe.iterrows():\n",
    "        current_row_values = row[columns].values\n",
    "        closest_keys = sorted(dictionary.keys(), key=lambda k: np.linalg.norm(np.array(k) - np.array(current_row_values)))\n",
    "        closest_values.append([dictionary[key] for key in closest_keys[:num]])\n",
    "\n",
    "    return closest_values\n",
    "\n",
    "#closest_values = find_closest_values(dictionary, final_df3[1:], ['Wing_P', 'Beak_P', 'Tail_P'], 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfb6572-877a-434c-954b-2c202da4ed13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee44e4d-8d5c-47f2-90bd-9884d0f70eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['id2'] = \"/train_images/\"+final_df['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5cfbda-8840-4a06-b155-e20fe87d5ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df2 = final_df.merge(train, left_on = 'id2', right_on = 'image_path')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbbebc7-5b53-408c-9fd9-e3fdab71130f",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df3 = final_df2[['id', '{}_P'.format(M1) , '{}_P'.format(M2), '{}_P'.format(M3), '{}'.format(M1), '{}'.format(M2), '{}'.format(M3), 'label']]\n",
    "final_df3.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc07a82-ae0a-4b30-b4c1-8337641c8acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7102541e-118a-4f1b-b505-a9a161920433",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "final_df3 = final_df2[['id', '{}_P'.format(M1), '{}_P'.format(M2), '{}_P'.format(M3), '{}'.format(M1), '{}'.format(M2), '{}'.format(M3), 'label']]\n",
    "#final_df3['estimates'] = closest_values\n",
    "\n",
    "closest_values = find_closest_values(dictionary, final_df3[1:], [ '{}_P'.format(M1), '{}_P'.format(M2), '{}_P'.format(M3)],20 )\n",
    "\n",
    "list_of_lists = [list(inner_array) for inner_array in closest_values]\n",
    "\n",
    "# Create a DataFrame with the converted lists\n",
    "new_df = pd.DataFrame({'predictions': list_of_lists})\n",
    "\n",
    "# Concatenate the new DataFrame with the existing DataFrame\n",
    "result_df = pd.concat([final_df3, new_df], axis=1)\n",
    "result_df['is_value_in_prediction'] = result_df.apply(lambda row: row['label'] in row['predictions'] if isinstance(row['predictions'], list) else False, axis=1)\n",
    "#result_df['is_value_in_prediction'] = result_df.apply(lambda row: row['label'] in row['predictions'], axis=1)\n",
    "\n",
    "\n",
    "# Count the number of columns with True values\n",
    "#num_columns_with_true = (result_df['is_value_in_prediction'] == True).any().sum()\n",
    "#len(result_df[result_df['is_value_in_prediction'] == True])\n",
    "len(result_df[result_df['is_value_in_prediction'] == True]) / len(result_df[result_df['is_value_in_prediction'] == False])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa9fda8-c590-420f-b33e-20bc04ded7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def find_closest_values(dictionary, dataframe, columns, num):\n",
    "    closest_values = []\n",
    "    closest_distances = []\n",
    "\n",
    "    for _, row in dataframe.iterrows():\n",
    "        current_row_values = row[columns].values\n",
    "        closest_keys = sorted(dictionary.keys(), key=lambda k: np.linalg.norm(np.array(k) - np.array(current_row_values)))\n",
    "        closest_classes = [dictionary[key] for key in closest_keys[:num]]\n",
    "        closest_dist = [np.linalg.norm(np.array(key) - np.array(current_row_values)) for key in closest_keys[:num]]\n",
    "        \n",
    "        closest_values.append(closest_classes)\n",
    "        closest_distances.append(closest_dist)\n",
    "\n",
    "    return closest_values, closest_distances\n",
    "closest_values = find_closest_values(dictionary, final_df3[1:], ['Wing_P', 'Beak_P', 'Tail_P'],40 )\n",
    "#closest_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aac3bfb-d82d-4332-b0d3-21fae5088f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c08f5f7-f092-41b2-89a1-2b102ec2c291",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['Wing_P', 'Mass_P', 'Tail_P']\n",
    "array = final_df3[cols].to_numpy().tolist()\n",
    "\n",
    "cols = ['Wing.Length', 'Tail.Length', 'Beak.Width', 'label']\n",
    "idea = final_df3[cols].sort_values(by=['label']).drop_duplicates()\n",
    "cols = ['Wing.Length', 'Tail.Length', 'Beak.Width']\n",
    "idea  = idea[cols]\n",
    "array2 = idea.to_numpy().tolist()\n",
    "#array2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5529c43-a1bd-4e1a-8546-eda017c1d563",
   "metadata": {},
   "outputs": [],
   "source": [
    "idea = list()\n",
    "for x in array:\n",
    "    idea.append(closest_indices_mask(array2, x, 3).tolist())\n",
    "indices_with_ones = [i for i, sublist in enumerate(idea) if 1 in sublist]\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0220872a-21ad-4481-9121-66174aa0204d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927e69b1-d8c3-4761-9798-ed934ce87c67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0311fc31-09b1-4c2c-a8cd-0a740a4a1ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "final_df['id2'] = \"/test_images/\"+final_df['id']\n",
    "final_df['label_predict'] = final_df['label_predict'].astype(int)\n",
    "final_df = final_df[['label_predict','id2']]\n",
    "\n",
    "idea = np.sort(train_image['label'].unique())\n",
    "idea2 = pd.DataFrame(idea)\n",
    "idea2['index1'] = idea2.index\n",
    "idea2.columns = ['values', 'index1']\n",
    "idea2['values'] = idea2['values'].astype(int)\n",
    "\n",
    "final_df4 = final_df.merge(test_image_path[['image_path','id']], left_on = 'id2', right_on='image_path')\n",
    "\n",
    "final_df4 = final_df4[['id','label_predict']]\n",
    "\n",
    "final_df2 = final_df4.merge(idea2, how = 'left', left_on = 'label_predict', right_on = 'index1')\n",
    "final_df3 = final_df2[['id','values']]\n",
    "#two issues the class values arent right\n",
    "final_df3.columns = ['id','label']\n",
    "final_df3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bc852c-8f48-465c-9891-99f139161a2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a672dc-cc4a-4290-b23e-674f2771c805",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df3.to_csv('output_folder/output.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885c943d-aa26-497a-b061-90c6089afd5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b923057-24fc-4014-bbde-884e2411a0f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820ba3c9-b563-4074-8edd-5286f9103546",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b78d1a-9fdc-4412-948b-68de182a2d0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da52c494-620a-4e15-8d10-ea63c50687e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483c99bb-1486-45ea-93b4-9641014fe3cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
