{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea55ff5a-5e53-42c2-97e9-0114d3713916",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aabb601c-5990-42cc-a2ba-ef7eb5c4c5ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping, found downloaded files in \"./feather-in-focus\" (use force=True to force download)\n"
     ]
    }
   ],
   "source": [
    "import opendatasets as od\n",
    "import pandas\n",
    " \n",
    "od.download(\"https://www.kaggle.com/competitions/feather-in-focus/data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbbef826-114f-41b5-95d1-5b877b5e4b13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-07 16:34:37.803276: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX512_VNNI\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-07 16:34:37.984116: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "#https://www.kaggle.com/code/chekoduadarsh/starters-guide-convolutional-xgboost/notebook\n",
    "#https://www.kaggle.com/code/pedrolucasbritodes/bird-image-classification-cnn-89-accuracy/notebook\n",
    "#https://stats.stackexchange.com/questions/404809/is-it-advisable-to-use-output-from-a-ml-model-as-a-feature-in-another-ml-model\n",
    "import os\n",
    "os.environ['TF_GPU_ALLOCATOR'] = 'cuda_malloc_async'\n",
    "import tensorflow as tf\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.applications import InceptionV3\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import random\n",
    "\n",
    "#how many epchos still revert\n",
    "patience1 = 1000\n",
    "\n",
    "# these are the decaying laying edit thing. think of a cool name \n",
    "patience2 = 4\n",
    "always_keep_percent_locked = 20\n",
    "start_unlocking_at = 80\n",
    "decay_by = 10\n",
    "\n",
    "blur_number = 4\n",
    "base_learning_rate = 0.001 \n",
    "#number before fine_tuning\n",
    "number_epcho1 = 20\n",
    "#number after fine_tuning\n",
    "number_epcho2 = 20\n",
    "number_class = 200\n",
    "#needs to be the same number of classes\n",
    "output_Neurons = 200\n",
    "Neurons = 512\n",
    "drop_out_rate = 0.3\n",
    "image_shape = (224,224)\n",
    "image_shape_full = (224,224,3)\n",
    "current_directory = \"feather-in-focus\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1012c847-693a-4760-9cdd-f80a96740d5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a1ccf2b-4ac4-4cae-aac6-0b88a172b3cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch-local/scur2079.4603773/ipykernel_1066137/4078724003.py:7: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  test_image_path['total_path'] = test_image_path['total_path'].str.replace(\"\\\\\", \"/\" )\n",
      "/scratch-local/scur2079.4603773/ipykernel_1066137/4078724003.py:13: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  train_image['total_path'] = train_image['total_path'].str.replace(\"\\\\\", \"/\" )\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>label</th>\n",
       "      <th>total_path</th>\n",
       "      <th>short_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/train_images/1.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>feather-in-focus/train_images/train_images/1.jpg</td>\n",
       "      <td>1.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/train_images/2.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>feather-in-focus/train_images/train_images/2.jpg</td>\n",
       "      <td>2.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/train_images/3.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>feather-in-focus/train_images/train_images/3.jpg</td>\n",
       "      <td>3.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/train_images/4.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>feather-in-focus/train_images/train_images/4.jpg</td>\n",
       "      <td>4.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/train_images/5.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>feather-in-focus/train_images/train_images/5.jpg</td>\n",
       "      <td>5.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            image_path label  \\\n",
       "0  /train_images/1.jpg     1   \n",
       "1  /train_images/2.jpg     1   \n",
       "2  /train_images/3.jpg     1   \n",
       "3  /train_images/4.jpg     1   \n",
       "4  /train_images/5.jpg     1   \n",
       "\n",
       "                                         total_path short_name  \n",
       "0  feather-in-focus/train_images/train_images/1.jpg      1.jpg  \n",
       "1  feather-in-focus/train_images/train_images/2.jpg      2.jpg  \n",
       "2  feather-in-focus/train_images/train_images/3.jpg      3.jpg  \n",
       "3  feather-in-focus/train_images/train_images/4.jpg      4.jpg  \n",
       "4  feather-in-focus/train_images/train_images/5.jpg      5.jpg  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading files \n",
    "class_names2 = np.load('feather-in-focus/class_names.npy', allow_pickle=True).item()\n",
    "\n",
    "#load all files because why not\n",
    "test_image_path = pd.read_csv('feather-in-focus/test_images_path.csv')\n",
    "test_image_path['total_path'] = current_directory + \"/test_images\" + test_image_path['image_path'] \n",
    "test_image_path['total_path'] = test_image_path['total_path'].str.replace(\"\\\\\", \"/\" )\n",
    "test_image = pd.read_csv('feather-in-focus/test_images_sample.csv')\n",
    "\n",
    "#importing training data \n",
    "train_image = pd.read_csv('feather-in-focus/train_images.csv')\n",
    "train_image['total_path'] = current_directory + \"/train_images\" + train_image['image_path']\n",
    "train_image['total_path'] = train_image['total_path'].str.replace(\"\\\\\", \"/\" )\n",
    "train_image['label'] = train_image['label'].apply(str)\n",
    "train_image['short_name'] = train_image['image_path'].str.rsplit('/', n=1).str[-1]\n",
    "train_image.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0c216ed-d088-45d8-a6f6-0d3e8f125e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to add a k-folds, i have stratified so it works a bit better\n",
    "train, valid = train_test_split(train_image, \n",
    "                    test_size=0.2,\n",
    "                    stratify = train_image['label'],\n",
    "                    random_state=420)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20988c59-a2ec-4344-aa18-f3da469dab0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#deleting images if they are there \n",
    "\n",
    "folder_path = \"custom_aug\"  # Replace 'path_to_folder' with the actual path to your folder\n",
    "\n",
    "# Iterate through all files in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    file_path = os.path.join(folder_path, filename)\n",
    "    \n",
    "    # Check if the file is an image (you might want to refine this check based on your specific file types)\n",
    "    if os.path.isfile(file_path) and (filename.endswith('.jpg') or filename.endswith('.png')):\n",
    "        os.remove(file_path)\n",
    "        #print(f\"Deleted: {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5787442a-4cfc-46f6-8b8f-b0f966a4ce7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#custom Augmentation \n",
    "import cv2\n",
    "from PIL import Image, ImageFilter\n",
    "\n",
    "persp_train_dataframe = pd.DataFrame(columns=['image_path','label','total_path','short_name'])\n",
    "persp_valid_dataframe = pd.DataFrame(columns=['image_path','label','total_path','short_name'])\n",
    "\n",
    "gs_train_dataframe = pd.DataFrame(columns=['image_path','label','total_path','short_name'])\n",
    "gs_valid_dataframe = pd.DataFrame(columns=['image_path','label','total_path','short_name'])\n",
    "\n",
    "blur_train_dataframe = pd.DataFrame(columns=['image_path','label','total_path','short_name'])\n",
    "blur_valid_dataframe = pd.DataFrame(columns=['image_path','label','total_path','short_name'])\n",
    "\n",
    "def custom_blur(dataframe, label, name, location, folder,final_df, blur_number):\n",
    "    img = Image.open(dataframe[location]).filter(ImageFilter.GaussianBlur(blur_number))\n",
    "    img.save(r'{}/blur_{}'.format(folder,dataframe[name]))\n",
    "\n",
    "    return pd.DataFrame({\"image_path\": ['{}/blur_{}'.format(folder,dataframe[name])],\n",
    "                      'label': [dataframe[label]],\n",
    "                      'total_path': ['{}/blur_{}'.format(folder,dataframe[name])],\n",
    "                      'short_name': ['blur_{}'.format(dataframe[name])]\n",
    "                      })\n",
    "\n",
    "def custom_grey_scale(dataframe, label, name, location, folder,final_df):\n",
    "    img = Image.open(dataframe[location]).convert('L')\n",
    "    img.save(r'{}/gs_{}'.format(folder,dataframe[name]))\n",
    "\n",
    "    return pd.DataFrame({\"image_path\": ['{}/gs_{}'.format(folder,dataframe[name])],\n",
    "                      'label': [dataframe[label]],\n",
    "                      'total_path': ['{}/gs_{}'.format(folder,dataframe[name])],\n",
    "                      'short_name': ['gs_{}'.format(dataframe[name])]\n",
    "                      })\n",
    "\n",
    "def custom_getPerspectiveTransform(dataframe, label, name, location, folder,final_df):\n",
    "    \n",
    "    \n",
    "    input_image = cv2.imread(dataframe[location])  # Replace 'path_to_your_image.jpg' with the actual path to your image\n",
    "    # need to variability\n",
    "    height, width = input_image.shape[:2]\n",
    "      \n",
    "   # Define destination points based on image size (20% of width and 30% of height)\n",
    "    objPoints = np.float32([[0, 0], \n",
    "                            [int(np.random.uniform(0.75, 0.85) * width), 0], \n",
    "                            [0, int(np.random.uniform(0.85, 0.95) * height)], \n",
    "                            [int(np.random.uniform(0.75, 0.85) * width), \n",
    "                             int(np.random.uniform(0.65, 0.75) * height)]])\n",
    "    imgPts = np.float32([\n",
    "    [np.random.uniform(0.10, 0.20) * width, np.random.uniform(0.20, 0.30) * height],  # 15% of width, 25% of height\n",
    "    [np.random.uniform(0.75, 0.85) * width, np.random.uniform(0.15, 0.25) * height],  # 80% of width, 20% of height\n",
    "    [np.random.uniform(0.05, 0.15) * width, np.random.uniform(0.65, 0.75) * height],  # 10% of width, 70% of height\n",
    "    [np.random.uniform(0.85, 0.95) * width, np.random.uniform(0.65, 0.75) * height]   # 90% of width, 70% of height\n",
    "    ])\n",
    "    \n",
    "    \n",
    "    #imgPts = np.float32([[114, 151], [605, 89], [72, 420], [637, 420]])\n",
    "    # need to add varibility\n",
    "    #objPoints = np.float32([[0, 0], [420, 0], [0, 637], [420, 637]])\n",
    "    matrix = cv2.getPerspectiveTransform(imgPts, objPoints)\n",
    "    result = cv2.warpPerspective(input_image, matrix, (width, height))\n",
    "    \n",
    "    cv2.imwrite(r'{}/persp_{}'.format(folder,dataframe[name]), result)\n",
    "\n",
    "    \n",
    "    return pd.DataFrame({\"image_path\": ['{}/persp_{}'.format(folder,dataframe[name])],\n",
    "                      'label': [dataframe[label]],\n",
    "                      'total_path': ['{}/persp_{}'.format(folder,dataframe[name])],\n",
    "                      'short_name': ['persp_{}'.format(dataframe[name])]\n",
    "                      })\n",
    "\n",
    "loc = \"custom_aug\" \n",
    "for index, row in train.iterrows():\n",
    "    persp_train_dataframe = pd.concat([persp_train_dataframe, \n",
    "           custom_getPerspectiveTransform(row, 'label', 'short_name', 'total_path', loc, persp_train_dataframe)], sort=False)\n",
    "    gs_train_dataframe = pd.concat([gs_train_dataframe, \n",
    "           custom_grey_scale(row, 'label', 'short_name', 'total_path', loc, gs_train_dataframe)], sort=False)\n",
    "    #blur_train_dataframe = pd.concat([blur_train_dataframe, \n",
    "           #custom_blur(row, 'label', 'short_name', 'total_path', loc, blur_train_dataframe,blur_number)], sort=False)\n",
    "    #print(row)\n",
    "train = pd.concat([train, persp_train_dataframe], sort=False)\n",
    "train = pd.concat([train, gs_train_dataframe], sort=False)\n",
    "#train = pd.concat([train, blur_train_dataframe], sort=False)\n",
    "\n",
    "for index, row in valid.iterrows():\n",
    "    persp_valid_dataframe = pd.concat([persp_valid_dataframe, \n",
    "               custom_getPerspectiveTransform(row, 'label', 'short_name', 'total_path', loc, persp_valid_dataframe)], sort=False)\n",
    "    gs_valid_dataframe = pd.concat([gs_valid_dataframe, \n",
    "           custom_grey_scale(row, 'label', 'short_name', 'total_path', loc, gs_valid_dataframe)], sort=False)\n",
    "    #blur_valid_dataframe = pd.concat([blur_valid_dataframe, \n",
    "           #custom_blur(row, 'label', 'short_name', 'total_path', loc, blur_valid_dataframe,blur_number)], sort=False)\n",
    "    #print(row)\n",
    "valid = pd.concat([valid, persp_valid_dataframe], sort=False)\n",
    "valid = pd.concat([valid, gs_valid_dataframe], sort=False)\n",
    "#valid = pd.concat([valid, blur_valid_dataframe], sort=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "096a4b42-83f7-4327-bac6-b7682529da62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>label</th>\n",
       "      <th>total_path</th>\n",
       "      <th>short_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1045</th>\n",
       "      <td>/train_images/1046.jpg</td>\n",
       "      <td>35</td>\n",
       "      <td>feather-in-focus/train_images/train_images/104...</td>\n",
       "      <td>1046.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3856</th>\n",
       "      <td>/train_images/3857.jpg</td>\n",
       "      <td>189</td>\n",
       "      <td>feather-in-focus/train_images/train_images/385...</td>\n",
       "      <td>3857.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>/train_images/377.jpg</td>\n",
       "      <td>13</td>\n",
       "      <td>feather-in-focus/train_images/train_images/377...</td>\n",
       "      <td>377.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1789</th>\n",
       "      <td>/train_images/1790.jpg</td>\n",
       "      <td>62</td>\n",
       "      <td>feather-in-focus/train_images/train_images/179...</td>\n",
       "      <td>1790.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1900</th>\n",
       "      <td>/train_images/1901.jpg</td>\n",
       "      <td>66</td>\n",
       "      <td>feather-in-focus/train_images/train_images/190...</td>\n",
       "      <td>1901.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>custom_aug/gs_2313.jpg</td>\n",
       "      <td>83</td>\n",
       "      <td>custom_aug/gs_2313.jpg</td>\n",
       "      <td>gs_2313.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>custom_aug/gs_3845.jpg</td>\n",
       "      <td>187</td>\n",
       "      <td>custom_aug/gs_3845.jpg</td>\n",
       "      <td>gs_3845.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>custom_aug/gs_2972.jpg</td>\n",
       "      <td>116</td>\n",
       "      <td>custom_aug/gs_2972.jpg</td>\n",
       "      <td>gs_2972.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>custom_aug/gs_296.jpg</td>\n",
       "      <td>11</td>\n",
       "      <td>custom_aug/gs_296.jpg</td>\n",
       "      <td>gs_296.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>custom_aug/gs_3359.jpg</td>\n",
       "      <td>140</td>\n",
       "      <td>custom_aug/gs_3359.jpg</td>\n",
       "      <td>gs_3359.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2358 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  image_path label  \\\n",
       "1045  /train_images/1046.jpg    35   \n",
       "3856  /train_images/3857.jpg   189   \n",
       "376    /train_images/377.jpg    13   \n",
       "1789  /train_images/1790.jpg    62   \n",
       "1900  /train_images/1901.jpg    66   \n",
       "...                      ...   ...   \n",
       "0     custom_aug/gs_2313.jpg    83   \n",
       "0     custom_aug/gs_3845.jpg   187   \n",
       "0     custom_aug/gs_2972.jpg   116   \n",
       "0      custom_aug/gs_296.jpg    11   \n",
       "0     custom_aug/gs_3359.jpg   140   \n",
       "\n",
       "                                             total_path   short_name  \n",
       "1045  feather-in-focus/train_images/train_images/104...     1046.jpg  \n",
       "3856  feather-in-focus/train_images/train_images/385...     3857.jpg  \n",
       "376   feather-in-focus/train_images/train_images/377...      377.jpg  \n",
       "1789  feather-in-focus/train_images/train_images/179...     1790.jpg  \n",
       "1900  feather-in-focus/train_images/train_images/190...     1901.jpg  \n",
       "...                                                 ...          ...  \n",
       "0                                custom_aug/gs_2313.jpg  gs_2313.jpg  \n",
       "0                                custom_aug/gs_3845.jpg  gs_3845.jpg  \n",
       "0                                custom_aug/gs_2972.jpg  gs_2972.jpg  \n",
       "0                                 custom_aug/gs_296.jpg   gs_296.jpg  \n",
       "0                                custom_aug/gs_3359.jpg  gs_3359.jpg  \n",
       "\n",
       "[2358 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31b8bb47-9f6c-4815-b420-60f7e3d321fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9420 validated image filenames belonging to 200 classes.\n",
      "Found 2358 validated image filenames belonging to 200 classes.\n"
     ]
    }
   ],
   "source": [
    "# this creates the type of augmentation that is done! \n",
    "datagen = ImageDataGenerator(\n",
    "    #rotation_range=15,\n",
    "    rotation_range=50,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range = 15,\n",
    "    horizontal_flip = True,\n",
    "    zoom_range = 0.20)\n",
    "#look at aug from group chat \n",
    "\n",
    "#okay this method seems WAY better. only ever use aug images\n",
    "train_generator=datagen.flow_from_dataframe(\n",
    "dataframe=train,\n",
    "x_col='total_path',\n",
    "y_col='label',\n",
    "#classes = train['label'].tolist(),\n",
    "color_mode = 'rgb',\n",
    "target_size = image_shape)\n",
    "\n",
    "valid_generator=datagen.flow_from_dataframe(\n",
    "dataframe=valid,\n",
    "x_col='total_path',\n",
    "y_col='label',\n",
    "#classes = valid['label'].tolist(),\n",
    "color_mode = 'rgb',\n",
    "target_size = image_shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e42ea244-aa84-47b7-b1c4-ed4298ce6dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "small_data = pd.DataFrame({'real_label': np.unique(train_image['label']), \n",
    "                           'keras_label':pd.DataFrame(np.unique(train_image['label'])).index})\n",
    "class_weights = train_image.merge(small_data, left_on = 'label', right_on = 'real_label')\n",
    "class_number = class_weights['keras_label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320bae1a-886b-4a97-b043-bfd6a88e3568",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416049e2-4547-49fb-999a-fcfdb4640f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class weights\n",
    "from sklearn.utils import compute_class_weight\n",
    "class_weights = compute_class_weight(\n",
    "                                        class_weight = \"balanced\",\n",
    "                                        classes = np.unique(class_number),\n",
    "                                        y = class_number                                                    \n",
    "                                    )\n",
    "\n",
    "class_weights = dict(zip(np.unique(class_number), class_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499ffce8-bf3d-436b-a197-2336a0e1a7bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5979149a-db5f-4ffa-8543-ffd08300102d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c4e3af-a22b-43d3-9834-e51721639c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# attempt 100000 to get multi api to work\n",
    "# Create the base model (ResNet50)\n",
    "base_model = tf.keras.applications.ResNet50(\n",
    "    include_top=False,\n",
    "    input_shape=image_shape_full,\n",
    "    pooling='avg',\n",
    "    weights='imagenet'\n",
    ")\n",
    "\n",
    "# Freeze the ResNet50 model layers\n",
    "base_model.trainable = False\n",
    "# Define the input layer\n",
    "inputs = tf.keras.Input(shape=image_shape_full)\n",
    "# Pass the input through the base model\n",
    "x = base_model(inputs, training=False)\n",
    "# Hidden layers with BatchNormalization and Dropout\n",
    "x = tf.keras.layers.Dense(Neurons, activation=\"relu\", \n",
    "                          kernel_regularizer=tf.keras.regularizers.l2(0.01))(x)\n",
    "#x = tf.keras.layers.Dense(Neurons, activation=\"relu\")(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Dropout(drop_out_rate)(x)\n",
    "\n",
    "#x = tf.keras.layers.Dense(Neurons, activation=\"relu\")(x)\n",
    "#x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "#x = tf.keras.layers.Dense(Neurons, activation=\"relu\")(x)\n",
    "#x = tf.keras.layers.BatchNormalization()(x)\n",
    "#x = tf.keras.layers.Dropout(drop_out_rate)(x)\n",
    "\n",
    "# Create the base model (ResNet50)\n",
    "base_model2 = tf.keras.applications.InceptionV3(\n",
    "    include_top=False,\n",
    "    input_shape=image_shape_full,\n",
    "    pooling='avg',\n",
    "    weights='imagenet'\n",
    ")\n",
    "\n",
    "# Freeze the ResNet50 model layers\n",
    "base_model2.trainable = False\n",
    "# Pass the input through the base model\n",
    "x2 = base_model2(inputs, training=False)\n",
    "# Hidden layers with BatchNormalization and Dropout\n",
    "x2 = tf.keras.layers.Dense(Neurons, activation=\"relu\", \n",
    "                          kernel_regularizer=tf.keras.regularizers.l2(0.01))(x2)\n",
    "#x2 = tf.keras.layers.Dense(Neurons, activation=\"relu\")(x2)\n",
    "x2 = tf.keras.layers.BatchNormalization()(x2)\n",
    "x2 = tf.keras.layers.Dropout(drop_out_rate)(x2)\n",
    "\n",
    "\n",
    "#x2 = tf.keras.layers.Dense(Neurons, activation=\"relu\")(x2)\n",
    "#x2 = tf.keras.layers.BatchNormalization()(x2)\n",
    "\n",
    "#x2 = tf.keras.layers.Dense(Neurons, activation=\"relu\")(x2)\n",
    "#x2 = tf.keras.layers.BatchNormalization()(x2)\n",
    "#x2 = tf.keras.layers.Dropout(drop_out_rate)(x2)\n",
    "\n",
    "\n",
    "# combine \n",
    "weighted_average = tf.keras.layers.Average()([x,x2])\n",
    "#combined_predictions = tf.keras.layers.Concatenate()([dense2_res, dense2_invepV3])\n",
    "\n",
    "# Output layer\n",
    "outputs = tf.keras.layers.Dense(output_Neurons, activation=\"softmax\", name=\"output_layer\")(weighted_average)\n",
    "\n",
    "# Create the model\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "# Adam optimizer\n",
    "adam_optimizer = tf.keras.optimizers.Adam(learning_rate=base_learning_rate)\n",
    "\n",
    "# Compile the model \n",
    "model.compile(\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    optimizer=adam_optimizer,\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb07aea2-099c-4e6c-b825-135f04753f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# this is supposed to help with over-fitting\n",
    "#Setting the early_stop to avoid overfitting\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "    patience=patience1,\n",
    "    min_delta=0.001,\n",
    "    restore_best_weights=True,)\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs= number_epcho1,\n",
    "   # steps_per_epoch=len(train_generator),\n",
    "    validation_data=valid_generator,\n",
    "    #validation_steps=int(0.2 * len(valid_generator)),\n",
    "    callbacks=[early_stop],\n",
    "    class_weight=class_weights\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ce402a-c6c2-4e0a-9f4d-137161dc61d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from matplotlib import pyplot as plt\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a339a678",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x = reversed(range(always_keep_percent_locked, start_unlocking_at + decay_by ,decay_by))\n",
    "for n in x:\n",
    "    continue\n",
    "    base_model.trainable = True\n",
    "    #number of base model layers 80 % of base model \n",
    "    fine_tune_at = (len(base_model.layers) // 100) * n\n",
    "    # 176 layers in base 1\n",
    "    # Freeze all the layers before the `fine_tune_at` layer\n",
    "    for layer in base_model.layers[:fine_tune_at]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    base_model2.trainable = True    \n",
    "    #number of base model layers 80 % of base model \n",
    "    fine_tune_at = (len(base_model2.layers) // 100) * n\n",
    "    # 312 layers in base_model2\n",
    "    # Freeze all the layers before the `fine_tune_at` layer\n",
    "    for layer in base_model2.layers[:fine_tune_at]:\n",
    "        layer.trainable = False  \n",
    "    # Now that we will allow some layers to be unfreezed, it's better to decrease the learning rate to avoid dramatic changes in those \n",
    "    adam_optimizer = tf.keras.optimizers.Adam(learning_rate=base_learning_rate/100)\n",
    "\n",
    "    # Compile the model again\n",
    "    model.compile(\n",
    "        #loss = \"sparse_categorical_crossentropy\",\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        optimizer=adam_optimizer,\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "\n",
    "    early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "        patience=patience2,\n",
    "        min_delta=0.0001,\n",
    "        restore_best_weights=True,)\n",
    "\n",
    "    total_epochs = number_epcho1 + number_epcho1\n",
    "\n",
    "    history_fine = model.fit(\n",
    "                            train_generator,\n",
    "                             epochs=total_epochs,\n",
    "                             initial_epoch=history.epoch[-1],\n",
    "                             steps_per_epoch=len(train_generator),\n",
    "                             validation_data=valid_generator,\n",
    "                             validation_steps=int(0.25 * len(valid_generator)),\n",
    "                            callbacks=[early_stop],\n",
    "        class_weight=class_weights\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c71b72e-2c58-43e0-a77c-1873558068f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6096899-bb39-476c-a66d-6516687e4d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 80\n",
    "base_model.trainable = True\n",
    "#number of base model layers 80 % of base model \n",
    "fine_tune_at = (len(base_model.layers) // 100) * n\n",
    "# 176 layers in base 1\n",
    "# Freeze all the layers before the `fine_tune_at` layer\n",
    "for layer in base_model.layers[:fine_tune_at]:\n",
    "    layer.trainable = False\n",
    "\n",
    "base_model2.trainable = True    \n",
    "#number of base model layers 80 % of base model \n",
    "fine_tune_at = (len(base_model2.layers) // 100) * n\n",
    "# 312 layers in base_model2\n",
    "# Freeze all the layers before the `fine_tune_at` layer\n",
    "for layer in base_model2.layers[:fine_tune_at]:\n",
    "    layer.trainable = False  \n",
    "# Now that we will allow some layers to be unfreezed, it's better to decrease the learning rate to avoid dramatic changes in those \n",
    "adam_optimizer = tf.keras.optimizers.Adam(learning_rate=base_learning_rate/100)\n",
    "\n",
    "# Compile the model again\n",
    "model.compile(\n",
    "    #loss = \"sparse_categorical_crossentropy\",\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    optimizer=adam_optimizer,\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "    patience=patience2,\n",
    "    min_delta=0.0001,\n",
    "    restore_best_weights=True,)\n",
    "\n",
    "total_epochs = number_epcho1 + number_epcho1\n",
    "\n",
    "history_fine = model.fit(\n",
    "                        train_generator,\n",
    "                         epochs=total_epochs,\n",
    "                         initial_epoch=history.epoch[-1],\n",
    "                        # steps_per_epoch=len(train_generator),\n",
    "                         validation_data=valid_generator,\n",
    "                         #validation_steps=int(0.25 * len(valid_generator)),\n",
    "                        callbacks=[early_stop],\n",
    "    class_weight=class_weights\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd4a266-715a-4bd0-b6f5-9708bd635623",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from matplotlib import pyplot as plt\n",
    "plt.plot(history_fine.history['accuracy'])\n",
    "plt.plot(history_fine.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37765a38-cbcc-4ae5-bc40-b3fdfc22184c",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_directory = \"feather-in-focus\"\n",
    "model.save('{}/keras_final.keras'.format(current_directory))\n",
    "\n",
    "# image folder\n",
    "folder_path = '{}/test_images/test_images/'.format(current_directory)\n",
    "# path to model\n",
    "model_path = '{}/keras_final.keras'.format(current_directory)\n",
    "# dimensions of images\n",
    "img_width, img_height = 224, 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a09f44c-5270-4428-aa43-03f0a9b6726c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "import keras.utils as image\n",
    "# load the trained model\n",
    "adam_optimizer = tf.keras.optimizers.Adam(learning_rate=base_learning_rate)\n",
    "model_path = '{}/keras_final.keras'.format(current_directory)\n",
    "model = load_model(model_path)\n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "    optimizer=adam_optimizer,\n",
    "    metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfb8c1a-3551-4bb8-9440-2a311384c771",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = list()\n",
    "images = []\n",
    "folder_path = 'feather-in-focus/test_images/test_images'  # Your folder path containing images\n",
    "for img_name in os.listdir(folder_path):\n",
    "    img_path = os.path.join(folder_path, img_name)\n",
    "    # Check if the item is a file (not a directory)\n",
    "    if os.path.isfile(img_path):\n",
    "        name.append(img_name)\n",
    "        img = image.load_img(img_path, target_size=image_shape)\n",
    "        img = image.img_to_array(img)\n",
    "        \n",
    "        \n",
    "        #img_array = image.img_to_array(img)\n",
    "        #img = img.astype('float32') / 255.0  # Normalize pixel values\n",
    "\n",
    "# Reshape the image to a 4D tensor with a single sample (to match model input shape)\n",
    "        #img = img.reshape((1,) + img.shape)\n",
    "        \n",
    "        \n",
    "        img = np.expand_dims(img, axis=0)\n",
    "        images.append(img)\n",
    "        # Process the image further as needed\n",
    "    else:\n",
    "        # Skip directories\n",
    "        continue\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d812d7f-e48e-473d-9aa4-38697b8edc04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ea6649-cac1-4b50-ac15-8f755db542ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack up images list to pass for prediction\n",
    "images = np.vstack(images)\n",
    "classes = model.predict(images, batch_size=10)\n",
    "classes_x=np.argmax(classes,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0311fc31-09b1-4c2c-a8cd-0a740a4a1ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.DataFrame(\n",
    "    {'id': name,\n",
    "     'label_predict': classes_x\n",
    "    })\n",
    "\n",
    "final_df['id2'] = \"/test_images/\"+final_df['id']\n",
    "final_df['label_predict'] = final_df['label_predict'].astype(int)\n",
    "final_df = final_df[['label_predict','id2']]\n",
    "\n",
    "idea = np.sort(train_image['label'].unique())\n",
    "idea2 = pd.DataFrame(idea)\n",
    "idea2['index1'] = idea2.index\n",
    "idea2.columns = ['values', 'index1']\n",
    "idea2['values'] = idea2['values'].astype(int)\n",
    "\n",
    "final_df4 = final_df.merge(test_image_path[['image_path','id']], left_on = 'id2', right_on='image_path')\n",
    "\n",
    "final_df4 = final_df4[['id','label_predict']]\n",
    "\n",
    "final_df2 = final_df4.merge(idea2, how = 'left', left_on = 'label_predict', right_on = 'index1')\n",
    "final_df3 = final_df2[['id','values']]\n",
    "#two issues the class values arent right\n",
    "final_df3.columns = ['id','label']\n",
    "final_df3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a672dc-cc4a-4290-b23e-674f2771c805",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df3.to_csv('output_folder/output.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885c943d-aa26-497a-b061-90c6089afd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Define the metadata for your dataset\n",
    "metadata = {\n",
    "    \"title\": \"output.csv\",\n",
    "    \"id\": \"uvajonathon\",\n",
    "    \"licenses\": [\n",
    "        {\n",
    "            \"name\": \"License Name\",\n",
    "            \"id\": \"uvajonathon\",\n",
    "            \"url\": \"URL to License if applicable\"\n",
    "        }\n",
    "    ],\n",
    "    \"description\": \"Description of your dataset\",\n",
    "    \"keywords\": [\"keyword1\", \"keyword2\"],\n",
    "    \"language\": \"en\",\n",
    "    \"isPrivate\": False,  # Set to True or False based on privacy\n",
    "    \"collaborators\": [\"uvajonathon\"],\n",
    "    \"data\": [\n",
    "        {\n",
    "            \"description\": \"Description of the data\",\n",
    "            \"name\": \"output.csv\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Save the metadata to dataset-metadata.json\n",
    "file_path = 'output_folder/dataset-metadata.json'  # Specify the path where you want to save the file\n",
    "\n",
    "with open(file_path, 'w') as json_file:\n",
    "    json.dump(metadata, json_file, indent=4)\n",
    "\n",
    "print(f\"Dataset metadata saved to {file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b923057-24fc-4014-bbde-884e2411a0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "# Set the path to your Kaggle API credentials file (kaggle.json)\n",
    "os.environ['KAGGLE_CONFIG_DIR'] = '/gpfs/home2/scur2079/'\n",
    "# Instantiate the Kaggle API\n",
    "api = KaggleApi()\n",
    "# Replace 'competition-name' with the competition name (as shown in the competition URL)\n",
    "competition_name = 'feather-in-focus'\n",
    "# Replace 'file-path.csv' with the path to your CSV file\n",
    "file_path = '/gpfs/home2/scur2079/output_folder'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820ba3c9-b563-4074-8edd-5286f9103546",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Specify the competition to which you want to upload the file\n",
    "api.competition_name = competition_name\n",
    "# Upload the CSV file to the competition\n",
    "api.dataset_create_new(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa1c890d-a845-434b-9afd-33e921d88e83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x155294da8370>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "13b78d1a-9fdc-4412-948b-68de182a2d0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-05 15:14:52.610143: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8401\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/197 [..............................] - ETA: 17:14"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-05 15:14:54.857331: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "197/197 [==============================] - 70s 331ms/step\n"
     ]
    }
   ],
   "source": [
    "# Train your Keras model as described in your provided code\n",
    "\n",
    "# Assuming you've trained your Keras model and stored it in a variable 'model'\n",
    "from keras.models import Model\n",
    "# Extract features using the Keras Functional API\n",
    "# Create a new model that takes the same input as the previous model but outputs the output of the desired layer\n",
    "layer_name='output-layer'\n",
    "feature_extraction_model = Model(inputs=model.input,\n",
    "                                 outputs=model.get_layer(layer_name).output)\n",
    "\n",
    "\n",
    "# \n",
    "# Get features for training and validation data\n",
    "train_features = feature_extraction_model.predict(train_generator)  # Replace train_data with your actual training data\n",
    "#valid_features = feature_extraction_model.predict(valid)  # Replace valid_data with your actual validation data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1072233a-0e01-4de0-acb0-b52769386e92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "keras.preprocessing.image.DataFrameIterator"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3841d9b1-1acb-4592-9fcf-86c39b74cfe3",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "extract_labels() missing 1 required positional argument: 'label'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [31], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m labels \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m images, labels_batch \u001b[38;5;129;01min\u001b[39;00m train_generator:\n\u001b[0;32m----> 7\u001b[0m     labels\u001b[38;5;241m.\u001b[39mextend(\u001b[43mextract_labels\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels_batch\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mTypeError\u001b[0m: extract_labels() missing 1 required positional argument: 'label'"
     ]
    }
   ],
   "source": [
    "def extract_labels(image, label):\n",
    "    return label\n",
    "\n",
    "# Iterate through the generator to extract labels\n",
    "labels = []\n",
    "for images, labels_batch in train_generator:\n",
    "    labels.extend(extract_labels(images, labels_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4cd146b7-8457-4984-a4a9-0282f9af33a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "22dfd7fd-0162-494a-b51f-83bb2e8d5aab",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid classes inferred from unique values of `y`.  Expected: [0], got [dict_keys(['1', '10', '100', '101', '102', '103', '104', '105', '106', '107', '108', '109', '11', '110', '111', '112', '113', '114', '115', '116', '117', '118', '119', '12', '120', '121', '122', '123', '124', '125', '126', '127', '128', '129', '13', '130', '131', '132', '133', '134', '135', '136', '137', '138', '139', '14', '140', '141', '142', '143', '144', '145', '146', '147', '148', '149', '15', '150', '151', '152', '153', '154', '155', '156', '157', '158', '159', '16', '160', '161', '162', '163', '164', '165', '166', '167', '168', '169', '17', '170', '171', '172', '173', '174', '175', '176', '177', '178', '179', '18', '180', '181', '182', '183', '184', '185', '186', '187', '188', '189', '19', '190', '191', '192', '193', '194', '195', '196', '197', '198', '199', '2', '20', '200', '21', '22', '23', '24', '25', '26', '27', '28', '29', '3', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '4', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '5', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '6', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '7', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '8', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '9', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99'])]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [27], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mxgboost\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mxgb\u001b[39;00m\n\u001b[1;32m      3\u001b[0m xgb_model \u001b[38;5;241m=\u001b[39m xgb\u001b[38;5;241m.\u001b[39mXGBClassifier()  \u001b[38;5;66;03m# You can set hyperparameters as needed\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_indices\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/xgboost/core.py:729\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    727\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    728\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 729\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/xgboost/sklearn.py:1467\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m   1462\u001b[0m     expected_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\n\u001b[1;32m   1463\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1464\u001b[0m     classes\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m!=\u001b[39m expected_classes\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m   1465\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (classes \u001b[38;5;241m==\u001b[39m expected_classes)\u001b[38;5;241m.\u001b[39mall()\n\u001b[1;32m   1466\u001b[0m ):\n\u001b[0;32m-> 1467\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1468\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid classes inferred from unique values of `y`.  \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1469\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexpected_classes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclasses\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1470\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_xgb_params()\n\u001b[1;32m   1474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m callable(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective):\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid classes inferred from unique values of `y`.  Expected: [0], got [dict_keys(['1', '10', '100', '101', '102', '103', '104', '105', '106', '107', '108', '109', '11', '110', '111', '112', '113', '114', '115', '116', '117', '118', '119', '12', '120', '121', '122', '123', '124', '125', '126', '127', '128', '129', '13', '130', '131', '132', '133', '134', '135', '136', '137', '138', '139', '14', '140', '141', '142', '143', '144', '145', '146', '147', '148', '149', '15', '150', '151', '152', '153', '154', '155', '156', '157', '158', '159', '16', '160', '161', '162', '163', '164', '165', '166', '167', '168', '169', '17', '170', '171', '172', '173', '174', '175', '176', '177', '178', '179', '18', '180', '181', '182', '183', '184', '185', '186', '187', '188', '189', '19', '190', '191', '192', '193', '194', '195', '196', '197', '198', '199', '2', '20', '200', '21', '22', '23', '24', '25', '26', '27', '28', '29', '3', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '4', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '5', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '6', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '7', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '8', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '9', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99'])]"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "xgb_model = xgb.XGBClassifier()  # You can set hyperparameters as needed\n",
    "xgb_model.fit(train_features,labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1238ea9e-6c0b-4f97-a793-49c57341cc6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting xgboost\n",
      "  Downloading xgboost-2.0.2-py3-none-manylinux2014_x86_64.whl (297.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.1/297.1 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy in /gpfs/admin/_hpc/sw/arch/INTEL-AVX512/RHEL8/EB_production/2022/software/SciPy-bundle/2022.05-foss-2022a/lib/python3.10/site-packages (from xgboost) (1.22.3)\n",
      "Requirement already satisfied: scipy in /gpfs/admin/_hpc/sw/arch/INTEL-AVX512/RHEL8/EB_production/2022/software/SciPy-bundle/2022.05-foss-2022a/lib/python3.10/site-packages (from xgboost) (1.8.1)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-2.0.2\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 23.3.1 is available.\n",
      "You should consider upgrading via the '/sw/arch/RHEL8/EB_production/2022/software/Python/3.10.4-GCCcore-11.3.0/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "da52c494-620a-4e15-8d10-ea63c50687e4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'name' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [24], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Check if the item is a file (not a directory)\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(img_path):\n\u001b[0;32m----> 7\u001b[0m     \u001b[43mname\u001b[49m\u001b[38;5;241m.\u001b[39mappend(img_name)\n\u001b[1;32m      8\u001b[0m     img \u001b[38;5;241m=\u001b[39m image\u001b[38;5;241m.\u001b[39mload_img(img_path, target_size\u001b[38;5;241m=\u001b[39mimage_shape)\n\u001b[1;32m      9\u001b[0m     img \u001b[38;5;241m=\u001b[39m image\u001b[38;5;241m.\u001b[39mimg_to_array(img)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'name' is not defined"
     ]
    }
   ],
   "source": [
    "name = list()\n",
    "images = []\n",
    "from keras.models import load_model\n",
    "import keras.utils as image\n",
    "folder_path = 'feather-in-focus/test_images/test_images'  # Your folder path containing images\n",
    "for img_name in os.listdir(folder_path):\n",
    "    img_path = os.path.join(folder_path, img_name)\n",
    "    # Check if the item is a file (not a directory)\n",
    "    if os.path.isfile(img_path):\n",
    "        name.append(img_name)\n",
    "        img = image.load_img(img_path, target_size=image_shape)\n",
    "        img = image.img_to_array(img)\n",
    "        img = np.expand_dims(img, axis=0)\n",
    "        images.append(img)\n",
    "        # Process the image further as needed\n",
    "    else:\n",
    "        # Skip directories\n",
    "        continue\n",
    "        \n",
    "# stack up images list to pass for prediction\n",
    "images = np.vstack(images)\n",
    "classes = feature_extraction_model.predict(images, batch_size=10)\n",
    "classes_x=np.argmax(classes,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ff49b730-4777-4244-8922-1ce619171d0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "valid_features[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "483c99bb-1486-45ea-93b4-9641014fe3cf",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'name' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [21], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m classes_x\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39margmax(valid_features,axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      2\u001b[0m final_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\n\u001b[0;32m----> 3\u001b[0m     {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[43mname\u001b[49m,\n\u001b[1;32m      4\u001b[0m      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel_predict\u001b[39m\u001b[38;5;124m'\u001b[39m: classes_x\n\u001b[1;32m      5\u001b[0m     })\n\u001b[1;32m      7\u001b[0m final_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid2\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/test_images/\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39mfinal_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      8\u001b[0m final_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel_predict\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m final_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel_predict\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'name' is not defined"
     ]
    }
   ],
   "source": [
    "classes_x=np.argmax(valid_features,axis=1)\n",
    "final_df = pd.DataFrame(\n",
    "    {'id': name,\n",
    "     'label_predict': classes_x\n",
    "    })\n",
    "\n",
    "final_df['id2'] = \"/test_images/\"+final_df['id']\n",
    "final_df['label_predict'] = final_df['label_predict'].astype(int)\n",
    "final_df = final_df[['label_predict','id2']]\n",
    "\n",
    "idea = np.sort(train_image['label'].unique())\n",
    "idea2 = pd.DataFrame(idea)\n",
    "idea2['index1'] = idea2.index\n",
    "idea2.columns = ['values', 'index1']\n",
    "idea2['values'] = idea2['values'].astype(int)\n",
    "\n",
    "final_df4 = final_df.merge(test_image_path[['image_path','id']], left_on = 'id2', right_on='image_path')\n",
    "\n",
    "final_df4 = final_df4[['id','label_predict']]\n",
    "\n",
    "final_df2 = final_df4.merge(idea2, how = 'left', left_on = 'label_predict', right_on = 'index1')\n",
    "final_df3 = final_df2[['id','values']]\n",
    "#two issues the class values arent right\n",
    "final_df3.columns = ['id','label']\n",
    "final_df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582fc304-f43f-4c3a-b75f-445051a1ee0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
