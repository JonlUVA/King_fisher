{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea55ff5a-5e53-42c2-97e9-0114d3713916",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabb601c-5990-42cc-a2ba-ef7eb5c4c5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import opendatasets as od\n",
    "import pandas\n",
    " \n",
    "od.download(\"https://www.kaggle.com/competitions/feather-in-focus/data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbbef826-114f-41b5-95d1-5b877b5e4b13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-13 13:50:44.631836: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX512_VNNI\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-13 13:50:44.823422: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "#https://www.kaggle.com/code/chekoduadarsh/starters-guide-convolutional-xgboost/notebook\n",
    "#https://www.kaggle.com/code/pedrolucasbritodes/bird-image-classification-cnn-89-accuracy/notebook\n",
    "#https://stats.stackexchange.com/questions/404809/is-it-advisable-to-use-output-from-a-ml-model-as-a-feature-in-another-ml-model\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.applications import InceptionV3\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import random\n",
    "\n",
    "#how many epchos still revert\n",
    "patience1 = 3\n",
    "\n",
    "base_learning_rate = 0.001 \n",
    "#number before fine_tuning\n",
    "epchos1 =15\n",
    "#number after fine_tuning\n",
    "number_epcho2 = 20\n",
    "number_class = 200\n",
    "#needs to be the same number of classes\n",
    "output_Neurons = 200\n",
    "Neurons = 512\n",
    "batch_size = 32\n",
    "drop_out_rate = 0.3\n",
    "image_shape = (224,224)\n",
    "image_shape_full = (224,224,3)\n",
    "current_directory = \"feather-in-focus/\"\n",
    "#current_directory = \"feather-in-focus/\"\n",
    "blur_number = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a1ccf2b-4ac4-4cae-aac6-0b88a172b3cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch-local/scur2079.4639786/ipykernel_3936187/3679845827.py:7: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  test_image_path['total_path'] = test_image_path['total_path'].str.replace(\"\\\\\", \"/\" )\n",
      "/scratch-local/scur2079.4639786/ipykernel_3936187/3679845827.py:14: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  train_image['total_path'] = train_image['total_path'].str.replace(\"\\\\\", \"/\" )\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{1, 2, 3, 4, 5}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading files \n",
    "class_names2 = np.load('{}class_names.npy'.format(current_directory), allow_pickle=True).item()\n",
    "\n",
    "#load all files because why not\n",
    "test_image_path = pd.read_csv('{}test_images_path.csv'.format(current_directory))\n",
    "test_image_path['total_path'] = current_directory + \"/test_images\" + test_image_path['image_path'] \n",
    "test_image_path['total_path'] = test_image_path['total_path'].str.replace(\"\\\\\", \"/\" )\n",
    "test_image = pd.read_csv('{}test_images_sample.csv'.format(current_directory))\n",
    "\n",
    "\n",
    "#importing training data \n",
    "train_image = pd.read_csv('{}train_images.csv'.format(current_directory))\n",
    "train_image['total_path'] = current_directory + \"train_images\" + train_image['image_path']\n",
    "train_image['total_path'] = train_image['total_path'].str.replace(\"\\\\\", \"/\" )\n",
    "train_image['short_name'] = train_image['image_path'].str.rsplit('/', n=1).str[-1]\n",
    "\n",
    "#train_image['label'] = train_image['label'].apply(str)\n",
    "train_image.head()\n",
    "\n",
    "#importing bird data \n",
    "bird_data = pd.read_csv('{}output_birds.csv'.format(current_directory))\n",
    "\n",
    "\n",
    "bird_data2 = train_image.merge(bird_data, how = 'left', left_on = 'label', right_on = 'bird_number_x')\n",
    "bird_data2['label'] = bird_data2['label'].apply(str)\n",
    "\n",
    "\n",
    "M1 = 'Tarsus.Length'\n",
    "M2 = 'Hand-Wing.Index'\n",
    "M3 = 'Beak.Depth'\n",
    "c1 = 'Primary.Lifestyle'\n",
    "\n",
    "bird_data2 = bird_data2[['image_path','short_name', 'label', 'total_path', 'bird_class', M1,\n",
    "                        M2, M3, c1]]\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "#label_encoder = LabelEncoder()\n",
    "#ird_data2['encoded_labels'] = label_encoder.fit_transform(bird_data2[c1])\n",
    "bird_data2[c1] =  pd.factorize(bird_data2[c1])[0] +1\n",
    "# Convert encoded labels to one-hot encoded format\n",
    "set(bird_data2[c1].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5bc2d74-8a5d-4d7e-8459-a280f3515c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are no missing or null values in the DataFrame.\n"
     ]
    }
   ],
   "source": [
    "Wing_min = bird_data2[M1].min()\n",
    "Wing_max = bird_data2[M1].max()\n",
    "bird_data2[M1] =  (bird_data2[M1] - Wing_min) / (Wing_max - Wing_min)\n",
    "\n",
    "#Wing_mean = bird_data2['Wing.Length'].mean()\n",
    "#Wing_std = bird_data2['Wing.Length'].std()\n",
    "#bird_data2['Wing.Length'] =  (bird_data2['Wing.Length'] - Wing_mean) / (Wing_std)\n",
    "\n",
    "\n",
    "tail_min = bird_data2[M2].min()\n",
    "tail_max = bird_data2[M2].max()\n",
    "#tail_mean = bird_data2['Tail.Length'].mean()\n",
    "#tail_std = bird_data2['Tail.Length'].std()\n",
    "\n",
    "#bird_data2['Tail.Length'] = (bird_data2['Tail.Length'] - tail_mean ) / tail_std \n",
    "\n",
    "bird_data2[M2] = (bird_data2[M2] - tail_min ) / (tail_max - tail_min) \n",
    "mass_min = bird_data2[M3].min()\n",
    "mass_max = bird_data2[M3].max()\n",
    "#mass_mean = bird_data2['Beak.Width'].mean()\n",
    "#mass_std = bird_data2['Beak.Width'].std()\n",
    "#bird_data2['Beak.Width'] = (bird_data2['Beak.Width'] - mass_mean) / mass_std\n",
    "bird_data2[M3] = (bird_data2[M3] - mass_min) / (mass_max - mass_min)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Check for missing or null values in any column\n",
    "if bird_data2[[M1,M2, M3]].isnull().values.any():\n",
    "    print(\"There are missing or null values in the DataFrame.\")\n",
    "    # Return True or perform necessary actions\n",
    "else:\n",
    "    print(\"There are no missing or null values in the DataFrame.\")\n",
    "    # Return False or proceed accordingly\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0c216ed-d088-45d8-a6f6-0d3e8f125e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to add a k-folds, i have stratified so it works a bit better\n",
    "train, valid = train_test_split(bird_data2, \n",
    "                    test_size=0.2,\n",
    "                    #stratify = train_image['label'],\n",
    "                    random_state=420)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9bc74e11-5eff-4f7c-a0fd-9587b39b139e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>short_name</th>\n",
       "      <th>label</th>\n",
       "      <th>total_path</th>\n",
       "      <th>bird_class</th>\n",
       "      <th>Tarsus.Length</th>\n",
       "      <th>Hand-Wing.Index</th>\n",
       "      <th>Beak.Depth</th>\n",
       "      <th>Primary.Lifestyle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/train_images/1.jpg</td>\n",
       "      <td>1.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>feather-in-focus/train_images/train_images/1.jpg</td>\n",
       "      <td>Black footed Albatross</td>\n",
       "      <td>0.673810</td>\n",
       "      <td>0.929712</td>\n",
       "      <td>0.613924</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/train_images/2.jpg</td>\n",
       "      <td>2.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>feather-in-focus/train_images/train_images/2.jpg</td>\n",
       "      <td>Black footed Albatross</td>\n",
       "      <td>0.673810</td>\n",
       "      <td>0.929712</td>\n",
       "      <td>0.613924</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/train_images/3.jpg</td>\n",
       "      <td>3.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>feather-in-focus/train_images/train_images/3.jpg</td>\n",
       "      <td>Black footed Albatross</td>\n",
       "      <td>0.673810</td>\n",
       "      <td>0.929712</td>\n",
       "      <td>0.613924</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/train_images/4.jpg</td>\n",
       "      <td>4.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>feather-in-focus/train_images/train_images/4.jpg</td>\n",
       "      <td>Black footed Albatross</td>\n",
       "      <td>0.673810</td>\n",
       "      <td>0.929712</td>\n",
       "      <td>0.613924</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/train_images/5.jpg</td>\n",
       "      <td>5.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>feather-in-focus/train_images/train_images/5.jpg</td>\n",
       "      <td>Black footed Albatross</td>\n",
       "      <td>0.673810</td>\n",
       "      <td>0.929712</td>\n",
       "      <td>0.613924</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3921</th>\n",
       "      <td>/train_images/3922.jpg</td>\n",
       "      <td>3922.jpg</td>\n",
       "      <td>200</td>\n",
       "      <td>feather-in-focus/train_images/train_images/392...</td>\n",
       "      <td>Common Yellowthroat</td>\n",
       "      <td>0.140476</td>\n",
       "      <td>0.153355</td>\n",
       "      <td>0.033755</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3922</th>\n",
       "      <td>/train_images/3923.jpg</td>\n",
       "      <td>3923.jpg</td>\n",
       "      <td>200</td>\n",
       "      <td>feather-in-focus/train_images/train_images/392...</td>\n",
       "      <td>Common Yellowthroat</td>\n",
       "      <td>0.140476</td>\n",
       "      <td>0.153355</td>\n",
       "      <td>0.033755</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3923</th>\n",
       "      <td>/train_images/3924.jpg</td>\n",
       "      <td>3924.jpg</td>\n",
       "      <td>200</td>\n",
       "      <td>feather-in-focus/train_images/train_images/392...</td>\n",
       "      <td>Common Yellowthroat</td>\n",
       "      <td>0.140476</td>\n",
       "      <td>0.153355</td>\n",
       "      <td>0.033755</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3924</th>\n",
       "      <td>/train_images/3925.jpg</td>\n",
       "      <td>3925.jpg</td>\n",
       "      <td>200</td>\n",
       "      <td>feather-in-focus/train_images/train_images/392...</td>\n",
       "      <td>Common Yellowthroat</td>\n",
       "      <td>0.140476</td>\n",
       "      <td>0.153355</td>\n",
       "      <td>0.033755</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3925</th>\n",
       "      <td>/train_images/3926.jpg</td>\n",
       "      <td>3926.jpg</td>\n",
       "      <td>200</td>\n",
       "      <td>feather-in-focus/train_images/train_images/392...</td>\n",
       "      <td>Common Yellowthroat</td>\n",
       "      <td>0.140476</td>\n",
       "      <td>0.153355</td>\n",
       "      <td>0.033755</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3926 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  image_path short_name label  \\\n",
       "0        /train_images/1.jpg      1.jpg     1   \n",
       "1        /train_images/2.jpg      2.jpg     1   \n",
       "2        /train_images/3.jpg      3.jpg     1   \n",
       "3        /train_images/4.jpg      4.jpg     1   \n",
       "4        /train_images/5.jpg      5.jpg     1   \n",
       "...                      ...        ...   ...   \n",
       "3921  /train_images/3922.jpg   3922.jpg   200   \n",
       "3922  /train_images/3923.jpg   3923.jpg   200   \n",
       "3923  /train_images/3924.jpg   3924.jpg   200   \n",
       "3924  /train_images/3925.jpg   3925.jpg   200   \n",
       "3925  /train_images/3926.jpg   3926.jpg   200   \n",
       "\n",
       "                                             total_path  \\\n",
       "0      feather-in-focus/train_images/train_images/1.jpg   \n",
       "1      feather-in-focus/train_images/train_images/2.jpg   \n",
       "2      feather-in-focus/train_images/train_images/3.jpg   \n",
       "3      feather-in-focus/train_images/train_images/4.jpg   \n",
       "4      feather-in-focus/train_images/train_images/5.jpg   \n",
       "...                                                 ...   \n",
       "3921  feather-in-focus/train_images/train_images/392...   \n",
       "3922  feather-in-focus/train_images/train_images/392...   \n",
       "3923  feather-in-focus/train_images/train_images/392...   \n",
       "3924  feather-in-focus/train_images/train_images/392...   \n",
       "3925  feather-in-focus/train_images/train_images/392...   \n",
       "\n",
       "                  bird_class  Tarsus.Length  Hand-Wing.Index  Beak.Depth  \\\n",
       "0     Black footed Albatross       0.673810         0.929712    0.613924   \n",
       "1     Black footed Albatross       0.673810         0.929712    0.613924   \n",
       "2     Black footed Albatross       0.673810         0.929712    0.613924   \n",
       "3     Black footed Albatross       0.673810         0.929712    0.613924   \n",
       "4     Black footed Albatross       0.673810         0.929712    0.613924   \n",
       "...                      ...            ...              ...         ...   \n",
       "3921     Common Yellowthroat       0.140476         0.153355    0.033755   \n",
       "3922     Common Yellowthroat       0.140476         0.153355    0.033755   \n",
       "3923     Common Yellowthroat       0.140476         0.153355    0.033755   \n",
       "3924     Common Yellowthroat       0.140476         0.153355    0.033755   \n",
       "3925     Common Yellowthroat       0.140476         0.153355    0.033755   \n",
       "\n",
       "      Primary.Lifestyle  \n",
       "0                     1  \n",
       "1                     1  \n",
       "2                     1  \n",
       "3                     1  \n",
       "4                     1  \n",
       "...                 ...  \n",
       "3921                  4  \n",
       "3922                  4  \n",
       "3923                  4  \n",
       "3924                  4  \n",
       "3925                  4  \n",
       "\n",
       "[3926 rows x 9 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#valid = pd.read_csv('valid_csv.csv')\n",
    "#train = pd.read_csv('train_csv.csv')\n",
    "#valid['label'] = valid['label'].astype(str)\n",
    "#train['label'] = train['label'].astype(str)\n",
    "bird_data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77e25921-7d8b-4b3d-bcf1-70617596cf77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#deleting images if they are there \n",
    "\n",
    "folder_path = \"custom_aug\"  # Replace 'path_to_folder' with the actual path to your folder\n",
    "\n",
    "# Iterate through all files in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    file_path = os.path.join(folder_path, filename)\n",
    "    \n",
    "    # Check if the file is an image (you might want to refine this check based on your specific file types)\n",
    "    if os.path.isfile(file_path) and (filename.endswith('.jpg') or filename.endswith('.png')):\n",
    "        os.remove(file_path)\n",
    "        #print(f\"Deleted: {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbecc552-6ca0-4e90-af90-6d140f55cc01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47aacb31-9885-47e8-97a5-1da94b3132bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from PIL import Image, ImageFilter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def custom_blur(dataframe, label, name, folder, blur_number):\n",
    "    img = Image.open(dataframe['total_path']).filter(ImageFilter.GaussianBlur(blur_number))\n",
    "    img.save(f\"{folder}/blur_{dataframe[name]}\")\n",
    "\n",
    "    return {\n",
    "        \"image_path\": f\"{folder}/blur_{dataframe[name]}\",\n",
    "        M1: dataframe[M1],\n",
    "        M2: dataframe[M2],\n",
    "        M3: dataframe[M3],\n",
    "        c1: dataframe[c1],\n",
    "        \"total_path\": f\"{folder}/blur_{dataframe[name]}\",\n",
    "        \"short_name\": f\"blur_{dataframe[name]}\",\n",
    "        \"label\": dataframe[label],\n",
    "    }\n",
    "\n",
    "\n",
    "def custom_grey_scale(dataframe, label, name, location, folder):\n",
    "    img = Image.open(dataframe[location]).convert('L')\n",
    "    img.save(f\"{folder}/gs_{dataframe[name]}\")\n",
    "\n",
    "    return {\n",
    "        \"image_path\": f\"{folder}/gs_{dataframe[name]}\",\n",
    "        M1: dataframe[M1],\n",
    "        M2: dataframe[M2],\n",
    "        M3: dataframe[M3],\n",
    "        c1: dataframe[c1],\n",
    "        \"total_path\": f\"{folder}/gs_{dataframe[name]}\",\n",
    "        \"short_name\": f\"gs_{dataframe[name]}\",\n",
    "        \"label\": dataframe[label],\n",
    "    }\n",
    "\n",
    "\n",
    "def custom_getPerspectiveTransform(dataframe, label, name, folder):\n",
    "    input_image = cv2.imread(dataframe['total_path'])\n",
    "    height, width = input_image.shape[:2]\n",
    "    \n",
    "    objPoints = np.float32([[0, 0], \n",
    "                            [int(np.random.uniform(0.75, 0.85) * width), 0], \n",
    "                            [0, int(np.random.uniform(0.85, 0.95) * height)], \n",
    "                            [int(np.random.uniform(0.75, 0.85) * width), int(np.random.uniform(0.65, 0.75) * height)]])\n",
    "    \n",
    "    imgPts = np.float32([\n",
    "        [np.random.uniform(0.10, 0.20) * width, np.random.uniform(0.20, 0.30) * height],\n",
    "        [np.random.uniform(0.75, 0.85) * width, np.random.uniform(0.15, 0.25) * height],\n",
    "        [np.random.uniform(0.05, 0.15) * width, np.random.uniform(0.65, 0.75) * height],\n",
    "        [np.random.uniform(0.85, 0.95) * width, np.random.uniform(0.65, 0.75) * height]\n",
    "    ])\n",
    "    \n",
    "    matrix = cv2.getPerspectiveTransform(imgPts, objPoints)\n",
    "    result = cv2.warpPerspective(input_image, matrix, (width, height))\n",
    "    \n",
    "    cv2.imwrite(f\"{folder}/persp_{dataframe[name]}\", result)\n",
    "\n",
    "    return {\n",
    "        \"image_path\": f\"{folder}/persp_{dataframe[name]}\",\n",
    "        M1: dataframe[M1],\n",
    "        M2: dataframe[M2],\n",
    "        M3: dataframe[M3],\n",
    "        c1: dataframe[c1],\n",
    "        \"total_path\": f\"{folder}/persp_{dataframe[name]}\",\n",
    "        \"short_name\": f\"persp_{dataframe[name]}\",\n",
    "        \"label\": dataframe[label],\n",
    "    }\n",
    "\n",
    "loc = \"custom_aug\" \n",
    "blur_number = 5  # Specify your blur number\n",
    "\n",
    "train_augmented_data = []\n",
    "valid_augmented_data = []\n",
    "\n",
    "for index, row in train.iterrows():\n",
    "    train_augmented_data.append(custom_getPerspectiveTransform(row, 'label', 'short_name', loc))\n",
    "    train_augmented_data.append(custom_blur(row, 'label', 'short_name', loc, blur_number))\n",
    "    train_augmented_data.append(custom_grey_scale(row, 'label', 'short_name','total_path', loc))\n",
    "    \n",
    "\n",
    "for index, row in valid.iterrows():\n",
    "    valid_augmented_data.append(custom_getPerspectiveTransform(row, 'label', 'short_name', loc))\n",
    "    valid_augmented_data.append(custom_blur(row, 'label', 'short_name', loc, blur_number))\n",
    "    valid_augmented_data.append(custom_grey_scale(row, 'label', 'short_name','total_path', loc))\n",
    "\n",
    "# Create augmented DataFrames\n",
    "persp_train_dataframe = pd.DataFrame(train_augmented_data)\n",
    "persp_valid_dataframe = pd.DataFrame(valid_augmented_data)\n",
    "\n",
    "# Concatenate augmented DataFrames with original DataFrames\n",
    "train = pd.concat([train, persp_train_dataframe], ignore_index=True, sort=False)\n",
    "valid = pd.concat([valid, persp_valid_dataframe], ignore_index=True, sort=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e858b8bd-8065-411e-af8e-58835f9bb35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#valid = pd.read_csv('valid_csv.csv')\n",
    "#train = pd.read_csv('train_csv.csv')\n",
    "#valid['label'] = valid['label'].astype(str)\n",
    "#train['label'] = train['label'].astype(str)\n",
    "#train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23b9745-627c-4dc6-9296-1b8c0b3d212d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this creates the type of augmentation that is done! \n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    #rotation_range=15,\n",
    "    rotation_range=90,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range = 15,\n",
    "    horizontal_flip = True,\n",
    "    zoom_range = 0.20)\n",
    "#look at aug from group chat \n",
    "\n",
    "#okay this method seems WAY better. only ever use aug images\n",
    "train_generator = datagen.flow_from_dataframe(\n",
    "    dataframe=train,\n",
    "    x_col='total_path',\n",
    "    y_col=[M1,M2,M3],\n",
    "           # Assuming 'label' contains the continuous values\n",
    "    color_mode='rgb',\n",
    "    target_size=image_shape,\n",
    "    class_mode='raw',  # Use 'raw' for continuous values instead of 'categorical'\n",
    "    batch_size=batch_size  # Define your batch size\n",
    ")\n",
    "\n",
    "\n",
    "valid_generator = datagen.flow_from_dataframe(\n",
    "    dataframe=valid,\n",
    "    x_col='total_path',\n",
    "    y_col=[M1, M2, M3],\n",
    "    color_mode='rgb',\n",
    "    target_size=image_shape,\n",
    "    class_mode='raw',\n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218fab6b-c21b-4929-b78d-0c453f669887",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0755f8a6-8ebd-45b1-bca1-f7006be740f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5790fb1a-c369-4cf9-8da9-d6349d82272f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import ResNet50, InceptionV3\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, BatchNormalization, Dropout, GlobalAveragePooling2D, Input\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout\n",
    "import tensorflow as tf\n",
    "\n",
    "dr = 0.4\n",
    "IM_WIDTH, IM_HEIGHT = 224, 224\n",
    "\n",
    "class MultiOutputBird():\n",
    "    def __init__(self):\n",
    "        self.base_model_resnet = ResNet50(\n",
    "            include_top=False,\n",
    "            input_shape=(IM_HEIGHT, IM_WIDTH, 3),\n",
    "            pooling='avg',\n",
    "            weights='imagenet'\n",
    "        )\n",
    "        #self.base_model_resnet.trainable = False\n",
    "\n",
    "        self.base_model_inception = InceptionV3(\n",
    "            include_top=False,\n",
    "            input_shape=(IM_HEIGHT, IM_WIDTH, 3),\n",
    "            pooling='avg',\n",
    "            weights='imagenet'\n",
    "        )\n",
    "        \n",
    "        for layer in self.base_model_inception.layers[:-10]:\n",
    "            layer.trainable = False\n",
    "\n",
    "        for layer in self.base_model_resnet.layers[:-10]:\n",
    "            layer.trainable = False\n",
    "\n",
    "        #self.base_model_inception.trainable = False\n",
    "    def tail_length_branch(self, inputs, dropout_rate=0.3, l2_reg=0):\n",
    "        # Hidden layer 1\n",
    "        x = Dense(1024)(inputs)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = tf.keras.activations.relu(x)\n",
    "        x = Dropout(dropout_rate)(x)\n",
    "\n",
    "        # Hidden layer 2\n",
    "        x = Dense(512, activation=\"relu\", kernel_regularizer=tf.keras.regularizers.l2(l2_reg))(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = tf.keras.activations.relu(x)\n",
    "        x = Dropout(dropout_rate)(x)\n",
    "\n",
    "        # Hidden layer 3\n",
    "        x = Dense(512)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = tf.keras.activations.relu(x)\n",
    "\n",
    "        # Output layer\n",
    "        x = Dense(1, activation='sigmoid', name=\"{}_output\".format(M2))(x)\n",
    "        return x\n",
    "\n",
    "    def tail_length_branch(self, inputs, dropout_rate=0.3, l2_reg=0):   \n",
    "        x = Dense(1024)(inputs)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = tf.keras.activations.relu(x)\n",
    "        x = Dropout(dropout_rate)(x)\n",
    "\n",
    "        # Hidden layer 2\n",
    "        x = Dense(512, activation=\"relu\", kernel_regularizer=tf.keras.regularizers.l2(l2_reg))(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = tf.keras.activations.relu(x)\n",
    "        x = Dropout(dropout_rate)(x)\n",
    "\n",
    "        # Hidden layer 3\n",
    "        x = Dense(512)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = tf.keras.activations.relu(x)\n",
    "        \n",
    "        x = Dense(1, activation='sigmoid',  name='{}_output'.format(M2))(x)\n",
    "        return x\n",
    "\n",
    "    def beak_branch(self, inputs, dropout_rate=0.3, l2_reg=0):   \n",
    "        x = Dense(1024)(inputs)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = tf.keras.activations.relu(x)\n",
    "        x = Dropout(dropout_rate)(x)\n",
    "\n",
    "        # Hidden layer 2\n",
    "        x = Dense(512, activation=\"relu\", kernel_regularizer=tf.keras.regularizers.l2(l2_reg))(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = tf.keras.activations.relu(x)\n",
    "        x = Dropout(dropout_rate)(x)\n",
    "\n",
    "        # Hidden layer 3\n",
    "        x = Dense(512)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = tf.keras.activations.relu(x)\n",
    "        \n",
    "        x = Dense(1, activation='sigmoid', name=\"{}_output\".format(M3))(x)\n",
    "        return x\n",
    "    \n",
    "    def wing_length_branch(self, inputs, dropout_rate=0.3, l2_reg=0):   \n",
    "        x = Dense(1024)(inputs)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = tf.keras.activations.relu(x)\n",
    "        x = Dropout(dropout_rate)(x)\n",
    "\n",
    "        # Hidden layer 2\n",
    "        x = Dense(512, activation=\"relu\", kernel_regularizer=tf.keras.regularizers.l2(l2_reg))(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = tf.keras.activations.relu(x)\n",
    "        x = Dropout(dropout_rate)(x)\n",
    "\n",
    "        # Hidden layer 3\n",
    "        x = Dense(512)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = tf.keras.activations.relu(x)\n",
    "        \n",
    "        x = Dense(1, activation='sigmoid', name='{}_output'.format(M1))(x)\n",
    "        return x\n",
    "    \n",
    "    #def multi_class(self, inputs, dropout_rate=0.3, l2_reg=0.02, num_classes=len(set(bird_data2[c1].tolist()))):   \n",
    "        #x = Dense(1024)(inputs)\n",
    "        #x = BatchNormalization()(x)\n",
    "        #x = tf.keras.activations.relu(x)\n",
    "        #x = Dropout(dropout_rate)(x)\n",
    "\n",
    "        # Hidden layer 2\n",
    "        #x = Dense(512, activation=\"relu\", kernel_regularizer=tf.keras.regularizers.l2(l2_reg))(x)\n",
    "        #x = BatchNormalization()(x)\n",
    "        #x = tf.keras.activations.relu(x)\n",
    "       # x = Dropout(dropout_rate)(x)\n",
    "\n",
    "        # Hidden layer 3\n",
    "      #  x = Dense(512)(x)\n",
    "      #  x = BatchNormalization()(x)\n",
    "      #  x = tf.keras.activations.relu(x)\n",
    "\n",
    "      #  x = Dense(num_classes, activation='softmax', name=\"{}_output\".format(c1))(x)\n",
    "      #  return x\n",
    "\n",
    "    \n",
    "    def assemble_full_model(self):\n",
    "        input_resnet = Input(shape=(IM_HEIGHT, IM_WIDTH, 3))\n",
    "        input_inception = Input(shape=(IM_HEIGHT, IM_WIDTH, 3))\n",
    "\n",
    "        x_resnet = self.base_model_resnet(input_resnet)\n",
    "        x_inception = self.base_model_inception(input_resnet)\n",
    "\n",
    "        merged = tf.keras.layers.concatenate([x_resnet, x_inception])\n",
    "\n",
    "        M2_output = self.tail_length_branch(merged)\n",
    "        M3_output = self.beak_branch(merged)\n",
    "        M1_output = self.wing_length_branch(merged)\n",
    "        #c1_output = self.multi_class(merged)\n",
    "\n",
    "        model = Model(inputs=[input_resnet], outputs=[M1_output, M2_output, M3_output], name=\"multi_output_bird_net\")\n",
    "        return model\n",
    "\n",
    "# Example usage:\n",
    "model_builder = MultiOutputBird()\n",
    "model = model_builder.assemble_full_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a785ac50-2355-4f0b-b800-8549c013961a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a201662-9e64-40b8-9a8f-681ae0e1f459",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "epochs = 15\n",
    "adam_optimizer = tf.keras.optimizers.Adam(learning_rate=base_learning_rate)\n",
    "\n",
    "model.compile(optimizer=adam_optimizer,\n",
    "              loss={\n",
    "                  '{}_output'.format(M1): 'mse',\n",
    "                  '{}_output'.format(M2): 'mse',\n",
    "                  '{}_output'.format(M3): 'mse'\n",
    "                #'{}_output'.format(c1):  \"categorical_crossentropy\"\n",
    "                  \n",
    "              },\n",
    "              metrics={\n",
    "                  '{}_output'.format(M1): 'mae',\n",
    "                  '{}_output'.format(M2): 'mae',\n",
    "                  '{}_output'.format(M3): 'mae'\n",
    "                 # '{}_output'.format(c1):  \"accuracy\"\n",
    "              })\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25fa0cc-4374-46b6-9134-778aeb79599e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cec012-974f-448d-81f8-b78a9c1c2b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "    patience=10,\n",
    "    min_delta=0.001,\n",
    "    restore_best_weights=True,)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', patience=5, min_lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a63f0c0-68a6-45c8-9af8-a8280559e601",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_1 = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=valid_generator,\n",
    "    epochs=epchos1,\n",
    "    initial_epoch=epchos1,\n",
    "    batch_size=32,\n",
    "    callbacks=[reduce_lr, early_stop]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015889aa-ff4b-404d-ad6f-561dabaaa7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_1 = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=valid_generator,\n",
    "    epochs=epchos1 + 15,\n",
    "    initial_epoch=epchos1,\n",
    "    batch_size=32,\n",
    "    callbacks=[reduce_lr, early_stop]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d868fca-46ec-439f-882f-a6e24a7a93cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from matplotlib import pyplot as plt\n",
    "plt.clf() \n",
    "plt.plot(history.history['{}_output_mae'.format(M1)])\n",
    "plt.plot(history.history['val_{}_output_mae'.format(M1)])\n",
    "plt.title('model accuracy {}_output'.format(M1))\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.savefig('continous_result_{}.png'.format(M1))\n",
    "plt.clf() \n",
    "\n",
    "import keras\n",
    "from matplotlib import pyplot as plt\n",
    "plt.plot(history.history['{}_output_mae'.format(M2)])\n",
    "plt.plot(history.history['val_{}_output_mae'.format(M2)])\n",
    "plt.title('model accuracy {}'.format(M2))\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.savefig('continous_result_wing.png')\n",
    "plt.clf() \n",
    "\n",
    "\n",
    "import keras\n",
    "from matplotlib import pyplot as plt\n",
    "plt.plot(history.history['val_{}_output_mae'.format(M3)])\n",
    "plt.plot(history.history['{}_output_mae'.format(M3)])\n",
    "plt.title('model accuracy {}'.format(M3))\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.savefig('continous_result_tail.png'.format(M1))\n",
    "plt.clf() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55c6cfc-66f3-44a5-ac79-4a673696aa2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37765a38-cbcc-4ae5-bc40-b3fdfc22184c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "current_directory = \"feather-in-focus\"\n",
    "model.save('{}/keras_final_continous2.keras'.format(current_directory))\n",
    "\n",
    "\n",
    "# image folder\n",
    "folder_path = '{}/test_images/test_images/'.format(current_directory)\n",
    "# path to model\n",
    "model_path = '{}/keras_final_continous2.keras'.format(current_directory)\n",
    "# dimensions of images\n",
    "img_width, img_height = 224, 224\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a09f44c-5270-4428-aa43-03f0a9b6726c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "import keras.utils as image\n",
    "# load the trained model\n",
    "adam_optimizer = tf.keras.optimizers.Adam(learning_rate=base_learning_rate)\n",
    "model_path = '{}/keras_final_continous2.keras'.format(current_directory)\n",
    "model = load_model(model_path)\n",
    "model.compile(optimizer=adam_optimizer,\n",
    "              loss={\n",
    "                  '{}_output'.format(M1): 'mse',\n",
    "                  '{}_output'.format(M2): 'mse',\n",
    "                  '{}_output'.format(M3): 'mse'\n",
    "                #'{}_output'.format(c1):  \"accuracy\"\n",
    "                  \n",
    "              },\n",
    "              metrics={\n",
    "                  '{}_output'.format(M1): 'mae',\n",
    "                  '{}_output'.format(M2): 'mae',\n",
    "                  '{}_output'.format(M3): 'mae'\n",
    "                 # '{}_output'.format(c1):  \"accuracy\"\n",
    "              })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42881324-a0a4-4a0b-874f-c510dfc87961",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from heapq import nlargest\n",
    "\n",
    "def closest_indices_mask(array, value, num):\n",
    "    closest_indices = []\n",
    "    distances = []\n",
    "\n",
    "    for i, arr_value in enumerate(array):\n",
    "        distance = np.linalg.norm(np.array(arr_value) - np.array(value))\n",
    "        if len(closest_indices) < num:\n",
    "            closest_indices.append((i, distance))\n",
    "            distances.append(distance)\n",
    "        else:\n",
    "            max_distance = max(distances)\n",
    "            if distance < max_distance:\n",
    "                max_index = distances.index(max_distance)\n",
    "                closest_indices[max_index] = (i, distance)\n",
    "                distances[max_index] = distance\n",
    "\n",
    "    closest_indices.sort(key=lambda x: x[1])  # Sort by distance\n",
    "    closest_indices = [index for index, _ in closest_indices]\n",
    "\n",
    "    closest_mask = np.zeros_like(array)\n",
    "    closest_mask[closest_indices] = 1\n",
    "    return closest_mask[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfb8c1a-3551-4bb8-9440-2a311384c771",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = list()\n",
    "images = []\n",
    "folder_path = 'feather-in-focus/train_images/train_images'  \n",
    "#folder_path = 'feather-in-focus/test_images/test_images' \n",
    "for img_name in os.listdir(folder_path):\n",
    "    img_path = os.path.join(folder_path, img_name)\n",
    "    # Check if the item is a file (not a directory)\n",
    "    if os.path.isfile(img_path):\n",
    "        name.append(img_name)\n",
    "        img = image.load_img(img_path, target_size=image_shape)\n",
    "        img = image.img_to_array(img)\n",
    "        img = np.expand_dims(img, axis=0)\n",
    "        images.append(img)\n",
    "        # Process the image further as needed\n",
    "    else:\n",
    "        # Skip directories\n",
    "        continue\n",
    "        \n",
    "# stack up images list to pass for prediction\n",
    "images = np.vstack(images)\n",
    "classes = model.predict(images, batch_size=10)\n",
    "#classes_x=np.argmax(classes,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76975062-ddbf-4fa0-99da-eb6399a433ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [M1, M2, M3,c1, 'label']\n",
    "idea = bird_data2[cols].sort_values(by=['label']).drop_duplicates()\n",
    "cols = [M1, M2, M3]\n",
    "idea  = idea[cols]\n",
    "array2 = idea.to_numpy().tolist()\n",
    "\n",
    "result = [[classes[0][i], classes[1][i], classes[2][i]] for i in range(min(len(classes[0]), len(classes[1]), len(classes[2])))]\n",
    "distances = []\n",
    "for arr1 in result:\n",
    "    distances_to_arr1 = []\n",
    "    for arr2 in array2:\n",
    "        # Calculate Euclidean distance between elements in arr1 and arr2\n",
    "        distance = np.linalg.norm(np.array(arr1) - np.array(arr2))\n",
    "        distances_to_arr1.append(distance)\n",
    "    distances.append(distances_to_arr1)\n",
    "\n",
    "#print(distances)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17ede29-bd65-4e52-a489-86882228deb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns = [ '{}'.format(M1), '{}'.format(M2), '{}'.format(M3), c1, 'label']\n",
    "\n",
    "dictionary = dict()\n",
    "for index, row in bird_data2[selected_columns].iterrows():\n",
    "    key = (row['{}'.format(M1)], row['{}'.format(M2)], row['{}'.format(M3)])\n",
    "    value = row['label']\n",
    "    dictionary[key] = value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bffb285-f387-47dd-9daa-e9d03c711b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cols = [M1,M2,M3,c1 ,'label']\n",
    "idea = bird_data2[cols].sort_values(by=['label']).drop_duplicates()\n",
    "cols = [M1,M2,M3]\n",
    "idea  = idea[cols]\n",
    "array2 = idea.to_numpy().tolist()\n",
    "#array2\n",
    "\n",
    "\n",
    "result = [[classes[0][i], classes[1][i], classes[2][i]] for i in range(min(len(classes[0]), len(classes[1]), len(classes[2])))]\n",
    "distances = []\n",
    "for arr1 in result:\n",
    "    distances_to_arr1 = []\n",
    "    for arr2 in array2:\n",
    "        # Calculate Euclidean distance between elements in arr1 and arr2\n",
    "        distance = np.linalg.norm(np.array(arr1) - np.array(arr2))\n",
    "        distances_to_arr1.append(distance)\n",
    "    distances.append(distances_to_arr1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7729d27-0fdd-49e0-98b9-34bb0d641e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save numpy array as npy file\n",
    "from numpy import asarray\n",
    "from numpy import save\n",
    "# define data\n",
    "# save to npy file\n",
    "save('data_lookup.npy', array2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb5b73f-46d1-4ade-bd21-1be5f451ca92",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.DataFrame(\n",
    "    {'id': name,\n",
    "     '{}_P'.format(M1): classes[0].tolist(),\n",
    "     '{}_P'.format(M2): classes[1].tolist(),\n",
    "     '{}_P'.format(M3): classes[2].tolist(),\n",
    "     '{}_P'.format(c1): np.argmax(classes[3],axis=1),\n",
    "    })\n",
    "final_df['{}_P'.format(M1)] = final_df['{}_P'.format(M1)].apply(lambda x: float(x[0]))\n",
    "final_df['{}_P'.format(M2)] = final_df['{}_P'.format(M2)].apply(lambda x: float(x[0]))\n",
    "final_df['{}_P'.format(M3)] = final_df['{}_P'.format(M3)].apply(lambda x: float(x[0]))\n",
    "#final_df['{}_P'.format(c1)] = final_df['{}_P'.format(c1)].apply(lambda x: int(x[0]))\n",
    "\n",
    "final_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be762e59-9e45-46c4-831d-f92bf1a6bb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(final_df['{}_P'.format(c1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1e4580-0c85-4fb8-91b0-a31280c86dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def find_closest_values(dictionary, dataframe, columns,num):\n",
    "    closest_values = []\n",
    "\n",
    "    for _, row in dataframe.iterrows():\n",
    "        current_row_values = row[columns].values\n",
    "        closest_keys = sorted(dictionary.keys(), key=lambda k: np.linalg.norm(np.array(k) - np.array(current_row_values)))\n",
    "        closest_values.append([dictionary[key] for key in closest_keys[:num]])\n",
    "\n",
    "    return closest_values\n",
    "\n",
    "#closest_values = find_closest_values(dictionary, final_df3[1:], ['Wing_P', 'Beak_P', 'Tail_P'], 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfb6572-877a-434c-954b-2c202da4ed13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee44e4d-8d5c-47f2-90bd-9884d0f70eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['id2'] = \"/train_images/\"+final_df['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5cfbda-8840-4a06-b155-e20fe87d5ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df2 = final_df.merge(train, left_on = 'id2', right_on = 'image_path')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbbebc7-5b53-408c-9fd9-e3fdab71130f",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df3 = final_df2[['id', '{}_P'.format(M1) , '{}_P'.format(M2), '{}_P'.format(M3), '{}'.format(M1), '{}'.format(M2), '{}'.format(M3), 'label','{}'.format(c1), '{}_P'.format(M3)]]\n",
    "final_df3.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc07a82-ae0a-4b30-b4c1-8337641c8acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7102541e-118a-4f1b-b505-a9a161920433",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "final_df3 = final_df2[['id', '{}_P'.format(M1), '{}_P'.format(M2), '{}_P'.format(M3), '{}'.format(M1), '{}'.format(M2), '{}'.format(M3), 'label']]\n",
    "#final_df3['estimates'] = closest_values\n",
    "\n",
    "closest_values = find_closest_values(dictionary, final_df3[1:], [ '{}_P'.format(M1), '{}_P'.format(M2), '{}_P'.format(M3)],40 )\n",
    "\n",
    "list_of_lists = [list(inner_array) for inner_array in closest_values]\n",
    "\n",
    "# Create a DataFrame with the converted lists\n",
    "new_df = pd.DataFrame({'predictions': list_of_lists})\n",
    "\n",
    "# Concatenate the new DataFrame with the existing DataFrame\n",
    "result_df = pd.concat([final_df3, new_df], axis=1)\n",
    "result_df['is_value_in_prediction'] = result_df.apply(lambda row: row['label'] in row['predictions'] if isinstance(row['predictions'], list) else False, axis=1)\n",
    "#result_df['is_value_in_prediction'] = result_df.apply(lambda row: row['label'] in row['predictions'], axis=1)\n",
    "\n",
    "\n",
    "# Count the number of columns with True values\n",
    "#num_columns_with_true = (result_df['is_value_in_prediction'] == True).any().sum()\n",
    "#len(result_df[result_df['is_value_in_prediction'] == True])\n",
    "len(result_df[result_df['is_value_in_prediction'] == True]) / len(result_df[result_df['is_value_in_prediction'] == False])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa9fda8-c590-420f-b33e-20bc04ded7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def find_closest_values(dictionary, dataframe, columns, num):\n",
    "    closest_values = []\n",
    "    closest_distances = []\n",
    "\n",
    "    for _, row in dataframe.iterrows():\n",
    "        current_row_values = row[columns].values\n",
    "        closest_keys = sorted(dictionary.keys(), key=lambda k: np.linalg.norm(np.array(k) - np.array(current_row_values)))\n",
    "        closest_classes = [dictionary[key] for key in closest_keys[:num]]\n",
    "        closest_dist = [np.linalg.norm(np.array(key) - np.array(current_row_values)) for key in closest_keys[:num]]\n",
    "        \n",
    "        closest_values.append(closest_classes)\n",
    "        closest_distances.append(closest_dist)\n",
    "\n",
    "    return closest_values, closest_distances\n",
    "#closest_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aac3bfb-d82d-4332-b0d3-21fae5088f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5529c43-a1bd-4e1a-8546-eda017c1d563",
   "metadata": {},
   "outputs": [],
   "source": [
    "idea = list()\n",
    "for x in array:\n",
    "    idea.append(closest_indices_mask(array2, x, 3).tolist())\n",
    "indices_with_ones = [i for i, sublist in enumerate(idea) if 1 in sublist]\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0220872a-21ad-4481-9121-66174aa0204d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927e69b1-d8c3-4761-9798-ed934ce87c67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0311fc31-09b1-4c2c-a8cd-0a740a4a1ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "final_df['id2'] = \"/test_images/\"+final_df['id']\n",
    "final_df['label_predict'] = final_df['label_predict'].astype(int)\n",
    "final_df = final_df[['label_predict','id2']]\n",
    "\n",
    "idea = np.sort(train_image['label'].unique())\n",
    "idea2 = pd.DataFrame(idea)\n",
    "idea2['index1'] = idea2.index\n",
    "idea2.columns = ['values', 'index1']\n",
    "idea2['values'] = idea2['values'].astype(int)\n",
    "\n",
    "final_df4 = final_df.merge(test_image_path[['image_path','id']], left_on = 'id2', right_on='image_path')\n",
    "\n",
    "final_df4 = final_df4[['id','label_predict']]\n",
    "\n",
    "final_df2 = final_df4.merge(idea2, how = 'left', left_on = 'label_predict', right_on = 'index1')\n",
    "final_df3 = final_df2[['id','values']]\n",
    "#two issues the class values arent right\n",
    "final_df3.columns = ['id','label']\n",
    "final_df3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bc852c-8f48-465c-9891-99f139161a2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a672dc-cc4a-4290-b23e-674f2771c805",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df3.to_csv('output_folder/output.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885c943d-aa26-497a-b061-90c6089afd5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b923057-24fc-4014-bbde-884e2411a0f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820ba3c9-b563-4074-8edd-5286f9103546",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b78d1a-9fdc-4412-948b-68de182a2d0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da52c494-620a-4e15-8d10-ea63c50687e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483c99bb-1486-45ea-93b4-9641014fe3cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
